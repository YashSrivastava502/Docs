# app.py - Full Fixed Capacity Management Dashboard
# Fixes: UI more beautiful (icons, buttons, header, alerts, export CSV); Units consistent (inventory RAM MB->GB, events GB); Trends show flat if no events/baseline>0; Inventory RAM round 2 decimals + unit; Alternative if no trend: utilization pies; Added: Alerts for high util, summary stats, logging to txt (7 day retain); Inventory friendly column names
# Run with: python app.py
# Open: http://localhost:8050
# Requirements: pip install dash dash-bootstrap-components plotly pandas sqlalchemy psycopg2-binary

import base64
import io
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go  # For pies
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta
import logging
from logging.handlers import TimedRotatingFileHandler

from dash import Dash, dcc, html, Input, Output, State, callback, no_update
from dash import callback_context
import dash_bootstrap_components as dbc

from config import DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT

# ================= LOGGING SETUP =================
logger = logging.getLogger("dashboard_log")
logger.setLevel(logging.INFO)
handler = TimedRotatingFileHandler("dashboard.log", when="midnight", backupCount=7)  # 7 day retain
formatter = logging.Formatter('%(asctime)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ================= DB CONNECTION =================
ENGINE = create_engine(
    f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
    f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}",
    pool_pre_ping=True
)

# ================= HELPERS =================
def fmt(val, unit):
    val = float(val) if val else 0
    if unit == "CPU":
        return f"{int(val):,} cores"
    elif unit == "RAM":
        if val >= 1024:
            return f"{val/1024:.2f} TB"
        return f"{val:.2f} GB"
    elif unit == "STORAGE":
        if val >= 1024:
            return f"{val/1024:.2f} TB"
        return f"{val:.2f} GB"
    return f"{val:.2f}"

def parse_csv(contents, filename):
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    try:
        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        required = {'date', 'server', 'cpu', 'ram', 'storage'}
        if not required.issubset(df.columns.str.lower()):
            raise ValueError("CSV must contain columns: date, server, cpu, ram, storage")
        df.columns = df.columns.str.lower()
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])
        for col in ['cpu', 'ram', 'storage']:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        return df
    except Exception as e:
        raise ValueError(f"CSV parsing failed: {str(e)}")

# ================= CAPACITY CALCULATION =================
def calculate_capacity():
    try:
        inv = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric) / 1024.0, 0) AS ram_gb,  # MB to GB
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage_gb  # GB
            FROM inventory
        """, ENGINE)

        base = {
            "CPU": float(inv['cpu'].iloc[0]),
            "RAM": float(inv['ram_gb'].iloc[0]),
            "STORAGE": float(inv['storage_gb'].iloc[0])
        }

        ev = pd.read_sql("""
            SELECT
                COALESCE(SUM(cpu_delta), 0) AS cpu,
                COALESCE(SUM(ram_delta_gb), 0) AS ram_gb,
                COALESCE(SUM(storage_delta_gb), 0) AS storage_gb
            FROM capacity_events
        """, ENGINE)

        used = {
            "CPU": base["CPU"] + float(ev['cpu'].iloc[0]),
            "RAM": base["RAM"] + float(ev['ram_gb'].iloc[0]),
            "STORAGE": base["STORAGE"] + float(ev['storage_gb'].iloc[0])
        }

        result = {}
        for k in used:
            total = TOTAL_CAPACITY.get(k, 0)
            reserved = total * RESERVED_PERCENT
            usable = total - reserved
            used_k = max(used[k], 0)
            pct = (used_k / usable * 100) if usable > 0 else 0
            available = max(usable - used_k, 0)
            result[k] = {
                "used": used_k,
                "total": total,
                "reserved": reserved,
                "usable": usable,
                "available": available,
                "pct": pct
            }
        logger.info(f"Capacity calculated: {result}")
        return result
    except Exception as e:
        logger.error(f"Capacity error: {str(e)}")
        return {
            "CPU": {"used":0, "total":0, "reserved":0, "usable":0, "available":0, "pct":0},
            "RAM": {"used":0, "total":0, "reserved":0, "usable":0, "available":0, "pct":0},
            "STORAGE": {"used":0, "total":0, "reserved":0, "usable":0, "available":0, "pct":0}
        }

# ================= TREND FIGURE =================
def build_trend(resource):
    try:
        base = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric) / 1024.0, 0) AS ram,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage
            FROM inventory
        """, ENGINE)
        baseline = {
            "CPU": float(base['cpu'].iloc[0]),
            "RAM": float(base['ram'].iloc[0]),
            "STORAGE": float(base['storage'].iloc[0])
        }[resource]

        if baseline == 0:
            return px.line(title=f"No baseline for {resource}", template="plotly_white")

        today = datetime.today().date()
        thirty_days_ago = today - timedelta(days=30)

        df = pd.read_sql("""
            SELECT DATE(event_time) AS d,
                   SUM(CASE WHEN :r = 'CPU' THEN cpu_delta
                            WHEN :r = 'RAM' THEN ram_delta_gb
                            WHEN :r = 'STORAGE' THEN storage_delta_gb
                       END) AS v
            FROM capacity_events
            WHERE event_time >= :start_date
            GROUP BY DATE(event_time)
            ORDER BY d
        """, ENGINE, params={"r": resource, "start_date": thirty_days_ago})

        date_range = pd.date_range(start=thirty_days_ago, end=today)
        df = df.set_index('d').reindex(date_range).fillna(0).reset_index()
        df.columns = ['d', 'v']

        df['used'] = baseline + df['v'].cumsum()

        fig = px.line(df, x="d", y="used",
                      title=f"{resource} Trend (Last 30 Days)",
                      template="plotly_white",
                      color_discrete_sequence=["#198754"])
        fig.update_layout(
            height=300,
            margin=dict(l=20, r=20, t=40, b=40),
            xaxis_title="",
            yaxis_title="Used",
            font={"family": "Segoe UI", "size": 12, "color": "#333"}
        )
        return fig
    except Exception as e:
        logger.error(f"Trend error for {resource}: {str(e)}")
        return px.line(title="Trend unavailable")

# ================= UTIL PIE ================= (Alternative if trend fails)
def build_util_pie(util_pct):
    fig = go.Figure(go.Pie(
        labels=["Used", "Available"],
        values=[util_pct, 100 - min(util_pct, 100)],
        hole=0.4,
        marker_colors=["#dc3545", "#28a745"]
    ))
    fig.update_layout(
        height=300,
        title="Utilization Breakdown",
        showlegend=False,
        annotations=[{"text": f"{util_pct:.1f}%", "x":0.5, "y":0.5, "font_size":20, "showarrow":False}]
    )
    return fig

# ================= DASH APP =================
app = Dash(__name__, external_stylesheets=[dbc.themes.MINTY])
app.title = "Capacity Dashboard"

app.layout = dbc.Container([
    html.H1("Capacity Management Dashboard", className="text-center my-4", style={"color": "#198754", "fontFamily": "Segoe UI"}),

    dbc.Tabs([
        dbc.Tab(label="Dashboard", children=[
            dbc.Row([
                dbc.Col(html.H5("Current Capacity KPIs", className="text-center text-muted my-3"), width=12),
            ]),
            html.Div(id="kpi-alerts"),  # Added: Alerts for high util
            dbc.Row(id="kpi-row", className="g-4 justify-content-center mb-5"),

            dbc.Row([
                dbc.Col(html.H5("30-Day Usage Trends", className="text-center text-muted my-3"), width=12),
            ]),
            dbc.Row([
                dbc.Col(dcc.Graph(id="cpu-trend"), md=4),
                dbc.Col(dcc.Graph(id="ram-trend"), md=4),
                dbc.Col(dcc.Graph(id="storage-trend"), md=4),
            ]),
            # Added: Alternative pies if trends empty
            html.Div(id="util-pies", className="mt-4"),
            # Added: Refresh + Export
            dbc.Row([
                dbc.Col(dbc.Button("Refresh", id="refresh-btn", color="primary", className="me-2"), width=2),
                dbc.Col(dcc.Download(id="export-csv"), width=2),
                dbc.Col(dbc.Button("Export Inventory CSV", id="export-btn", color="secondary"), width=3),
            ], justify="center", className="mt-4")
        ]),

        dbc.Tab(label="Events", children=[
            dbc.Row([
                dbc.Col([
                    html.H6("Add New Event", className="mb-3 text-success"),
                    html.P("Instructions: Provide server name (mandatory). Use positive deltas to add capacity, negative to remove. At least one delta field must be non-zero. Example: For server 'srv-001', add 4 cores (+4 in CPU), 32 GB RAM (+32 in RAM). Submit to update KPIs/trends instantly.", className="small text-muted mb-3 p-2 bg-light rounded"),
                    dbc.InputGroup([
                        dbc.InputGroupText(html.I(className="bi bi-server")),  # Icon
                        dbc.Input(id="server", placeholder="Server Name (required)")
                    ], className="mb-2"),
                    dbc.InputGroup([
                        dbc.InputGroupText(html.I(className="bi bi-cpu")),
                        dbc.Input(id="cpu", type="number", placeholder="CPU Delta (cores)")
                    ], className="mb-2"),
                    dbc.InputGroup([
                        dbc.InputGroupText(html.I(className="bi bi-memory")),
                        dbc.Input(id="ram", type="number", placeholder="RAM Delta (GB)")
                    ], className="mb-2"),
                    dbc.InputGroup([
                        dbc.InputGroupText(html.I(className="bi bi-hdd")),
                        dbc.Input(id="storage", type="number", placeholder="Storage Delta (GB)")
                    ], className="mb-2"),
                    dbc.Button("Submit Event", id="submit", color="success", className="w-100"),
                    html.Div(id="msg", className="mt-3"),

                    html.Hr(className="my-4"),
                    html.H6("Bulk CSV Upload", className="mb-3 text-success"),
                    html.P("Instructions: Prepare CSV with headers: date (YYYY-MM-DD), server, cpu, ram, storage. Each row is an event. Upload to batch add.", className="small text-muted mb-3 p-2 bg-light rounded"),
                    dcc.Upload(
                        id="csv-upload",
                        children=dbc.Button("Upload CSV File", color="secondary", className="w-100"),
                        multiple=False
                    ),
                    html.Div(id="csv-msg", className="mt-3")
                ], md=4, className="p-4 bg-white rounded shadow"),

                dbc.Col([
                    html.H6("Recent Events (Last 10)", className="mb-3 text-success"),
                    html.Div(id="recent-events"),

                    html.Hr(),
                    html.H6("All Events (Last 100)", className="mb-3 text-success"),
                    html.Div(id="event-table")
                ], md=8)
            ], className="mt-4")
        ]),

        dbc.Tab(label="Inventory", children=[
            html.H5("Server Inventory (Read-Only)", className="text-center text-success my-4"),
            html.Div(id="inventory-table")
        ])
    ], className="shadow-lg rounded"),
    dcc.Interval(id="auto-refresh", interval=60*1000, n_intervals=0)

], fluid=True, className="py-5 bg-light")

# ================= CALLBACKS =================
@callback(
    Output("kpi-row", "children"),
    Output("cpu-trend", "figure"),
    Output("ram-trend", "figure"),
    Output("storage-trend", "figure"),
    Output("recent-events", "children"),
    Output("event-table", "children"),
    Output("inventory-table", "children"),
    Output("msg", "children"),
    Output("csv-msg", "children"),
    Output("kpi-alerts", "children"),
    Output("util-pies", "children"),
    Output("export-csv", "data"),
    Input("submit", "n_clicks"),
    Input("csv-upload", "contents"),
    Input("refresh-btn", "n_clicks"),
    Input("auto-refresh", "n_intervals"),
    Input("export-btn", "n_clicks"),
    State("server", "value"),
    State("cpu", "value"),
    State("ram", "value"),
    State("storage", "value"),
    State("csv-upload", "filename"),
    prevent_initial_call=False
)
def master_callback(submit_clicks, csv_contents, refresh_clicks, auto_n, export_clicks, server, cpu, ram, storage, csv_filename):
    ctx = callback_context
    triggered_id = ctx.triggered[0]['prop_id'].split('.')[0] if ctx.triggered else None

    msg_alert = no_update
    csv_alert = no_update
    export_data = no_update

    if triggered_id == "submit" and submit_clicks:
        if not server:
            msg_alert = dbc.Alert("Server required", color="danger")
        elif not (cpu or ram or storage):
            msg_alert = dbc.Alert("At least one delta required", color="danger")
        else:
            try:
                with ENGINE.begin() as conn:
                    conn.execute(text("""
                        INSERT INTO capacity_events (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source)
                        VALUES (:s, :c, :r, :st, 'MANUAL')
                    """), {"s": server, "c": float(cpu or 0), "r": float(ram or 0), "st": float(storage or 0)})
                msg_alert = dbc.Alert("Event saved", color="success")
                logger.info(f"Event added for {server}")
            except Exception as e:
                msg_alert = dbc.Alert(f"Error: {str(e)}", color="danger")
                logger.error(f"Event add error: {str(e)}")

    if triggered_id == "csv-upload" and csv_contents:
        try:
            df = parse_csv(csv_contents, csv_filename)
            with ENGINE.begin() as conn:
                for _, row in df.iterrows():
                    conn.execute(text("""
                        INSERT INTO capacity_events (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time)
                        VALUES (:server, :cpu, :ram, :storage, 'CSV', :dt)
                    """), {"server": row['server'], "cpu": row['cpu'], "ram": row['ram'], "storage": row['storage'], "dt": row['date']})
            csv_alert = dbc.Alert(f"Imported {len(df)} rows", color="success")
            logger.info(f"CSV imported: {len(df)} rows")
        except Exception as e:
            csv_alert = dbc.Alert(f"Error: {str(e)}", color="danger")
            logger.error(f"CSV import error: {str(e)}")

    if triggered_id == "export-btn" and export_clicks:
        inv_df = pd.read_sql("""
            SELECT assetuniquename AS "Server Name", assetipaddress AS "IP Address", servercores AS "CPU Cores",
                   ROUND((NULLIF(TRIM(servermemory), '')::numeric / 1024.0), 2) || ' GB' AS "RAM (GB)",
                   totaldisk AS "Total Disk (GB)", assetstatus AS "Status"
            FROM inventory ORDER BY assetuniquename
        """, ENGINE).fillna("NA")
        export_data = dcc.send_data_frame(inv_df.to_csv, "inventory.csv")
        logger.info("Inventory exported")

    cap = calculate_capacity()
    kpi_cards = []
    alerts = []
    pies = []
    for res, icon in [("CPU", "ðŸ–¥ï¸"), ("RAM", "ðŸ’¾"), ("STORAGE", "ðŸ—„ï¸")]:
        d = cap[res]
        bar_color = "danger" if d["pct"] > 100 else "warning" if d["pct"] > 75 else "success"
        kpi_cards.append(dbc.Col(
            dbc.Card([
                dbc.CardHeader(html.H6(f"{icon} {res}", className="text-white"), className="bg-success"),
                dbc.CardBody([
                    html.P(f"Total: {fmt(d['total'], res)}", className="small mb-1"),
                    html.P(f"Reserved: {fmt(d['reserved'], res)}", className="small mb-1"),
                    html.P(f"Usable: {fmt(d['usable'], res)}", className="small mb-1"),
                    html.P(f"Available: {fmt(d['available'], res)}", className="small mb-1"),
                    html.P(f"Used: {fmt(d['used'], res)}", className="small mb-2"),
                    dbc.Progress(value=d["pct"], color=bar_color, striped=True, animated=d["pct"] > 100, className="mb-2"),
                    html.Small(f"Utilization: {d['pct']:.1f}%", className="d-block text-center fw-bold")
                ])
            ], className="shadow h-100 rounded")
        , md=4, className="mb-3"))

        if d["pct"] > 90:
            alerts.append(dbc.Alert(f"{res} utilization high ({d['pct']:.1f}%) - Action needed!", color="warning", className="mb-2"))

        # Alternative pie if trend would be empty (but since trend works, optional)
        pies.append(dbc.Col(dcc.Graph(figure=build_util_pie(d["pct"])), md=4))

    cpu_fig = build_trend("CPU")
    ram_fig = build_trend("RAM")
    storage_fig = build_trend("STORAGE")

    recent_df = pd.read_sql("SELECT * FROM capacity_events ORDER BY event_time DESC LIMIT 10", ENGINE).fillna("NA")
    events_df = pd.read_sql("SELECT * FROM capacity_events ORDER BY event_time DESC LIMIT 100", ENGINE).fillna("NA")
    inv_df = pd.read_sql("""
        SELECT assetuniquename AS "Server Name", assetipaddress AS "IP Address", servercores AS "CPU Cores",
               ROUND((NULLIF(TRIM(servermemory), '')::numeric / 1024.0), 2) || ' GB' AS "RAM (GB)",
               totaldisk || ' GB' AS "Total Disk (GB)", assetstatus AS "Status"
        FROM inventory ORDER BY assetuniquename
    """, ENGINE).fillna("NA")

    recent_table = dbc.Table.from_dataframe(recent_df, striped=True, hover=True, responsive=True, bordered=True) if not recent_df.empty else html.P("No data", className="text-muted text-center")
    events_table = dbc.Table.from_dataframe(events_df, striped=True, hover=True, responsive=True, bordered=True) if not events_df.empty else html.P("No data", className="text-muted text-center")
    inv_table = dbc.Table.from_dataframe(inv_df, striped=True, hover=True, responsive=True, bordered=True) if not inv_df.empty else html.P("No data", className="text-muted text-center")

    return kpi_cards, cpu_fig, ram_fig, storage_fig, recent_table, events_table, inv_table, msg_alert, csv_alert, alerts, pies, export_data

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8050, debug=False)
