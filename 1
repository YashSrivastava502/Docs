# app.py - Final Advanced & Attractive Capacity Management Dashboard
# UI: Cerulean theme with gradients, icons, shadows, responsive layout, high util alerts, refresh/export buttons
# Data: KPIs from inventory + events, trends with baseline flat if no events, inventory with units/round
# Log: 7 day rotating txt file
# Run: python app.py
# Open: http://localhost:8050
# Requirements: pip install dash dash-bootstrap-components plotly pandas sqlalchemy psycopg2-binary

import base64
import io
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta
import logging
from logging.handlers import TimedRotatingFileHandler

from dash import Dash, dcc, html, Input, Output, State, callback, no_update
from dash import callback_context
import dash_bootstrap_components as dbc
from dash.dependencies import ALL

from config import DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT

# ================= LOGGING =================
logger = logging.getLogger("capacity_dash")
logger.setLevel(logging.INFO)
handler = TimedRotatingFileHandler("capacity.log", when="midnight", backupCount=7)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ================= DB =================
ENGINE = create_engine(
    f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
    f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}",
    pool_pre_ping=True
)

# ================= HELPERS =================
def fmt(val, unit):
    val = float(val) if val else 0
    if unit == "CPU":
        return f"{int(val):,} cores"
    if val >= 1024:
        return f"{val/1024:.2f} TB"
    return f"{val:.2f} GB"

def parse_csv(contents, filename):
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    try:
        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        required = {'date', 'server', 'cpu', 'ram', 'storage'}
        if not required.issubset(df.columns.str.lower()):
            raise ValueError("CSV must contain columns: date, server, cpu, ram, storage")
        df.columns = df.columns.str.lower()
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])
        for col in ['cpu', 'ram', 'storage']:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        return df
    except Exception as e:
        logger.error(f"CSV parse error: {str(e)}")
        raise ValueError(f"CSV parsing failed: {str(e)}")

# ================= CAPACITY CALC =================
def calculate_capacity():
    try:
        inv = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024, 0) AS ram,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage
            FROM inventory
        """, ENGINE)
        base = {
            "CPU": float(inv.cpu.iloc[0]),
            "RAM": float(inv.ram.iloc[0]),
            "STORAGE": float(inv.storage.iloc[0])
        }
        ev = pd.read_sql("""
            SELECT
                COALESCE(SUM(cpu_delta), 0) AS cpu,
                COALESCE(SUM(ram_delta_gb), 0) AS ram,
                COALESCE(SUM(storage_delta_gb), 0) AS storage
            FROM capacity_events
        """, ENGINE)
        used = {
            "CPU": base["CPU"] + float(ev.cpu.iloc[0]),
            "RAM": base["RAM"] + float(ev.ram.iloc[0]),
            "STORAGE": base["STORAGE"] + float(ev.storage.iloc[0])
        }
        result = {}
        for k in used:
            total = TOTAL_CAPACITY[k]
            reserved = total * RESERVED_PERCENT
            usable = total - reserved
            pct = (used[k] / usable * 100) if usable > 0 else 0
            available = max(usable - used[k], 0)
            result[k] = {
                "used": used[k],
                "total": total,
                "reserved": reserved,
                "usable": usable,
                "available": available,
                "pct": pct
            }
        logger.info("Capacity calculated")
        return result
    except Exception as e:
        logger.error(f"Capacity calc error: {str(e)}")
        return {k: {"used":0, "total":0, "reserved":0, "usable":0, "available":0, "pct":0} for k in ["CPU", "RAM", "STORAGE"]}

# ================= TREND =================
def build_trend(resource):
    try:
        base = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024, 0) AS ram,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage
            FROM inventory
        """, ENGINE)
        baseline = float(base[resource.lower()].iloc[0])

        today = datetime.today().date()
        thirty_days_ago = today - timedelta(days=30)

        df = pd.read_sql("""
            SELECT DATE(event_time) AS d,
                   SUM(CASE WHEN :r = 'CPU' THEN cpu_delta
                            WHEN :r = 'RAM' THEN ram_delta_gb
                            WHEN :r = 'STORAGE' THEN storage_delta_gb
                       END) AS v
            FROM capacity_events
            GROUP BY DATE(event_time)
            ORDER BY d
        """, ENGINE, params={"r": resource})

        if df.empty:
            df = pd.DataFrame({"d": [thirty_days_ago, today], "used": [baseline, baseline]})
            fig = px.line(df, x="d", y="used", title=f"{resource} Trend (Based on Inventory - No Events)", template="plotly_white")
        else:
            df = df.set_index('d').reindex(pd.date_range(thirty_days_ago, today)).fillna(0).reset_index()
            df.columns = ['d', 'v']
            df['used'] = baseline + df['v'].cumsum()
            fig = px.area(df, x="d", y="used", title=f"{resource} Trend (Inventory + Events)", template="plotly_white")

        fig.update_layout(height=350, xaxis_title="Date", yaxis_title="Used")
        return fig
    except Exception as e:
        logger.error(f"Trend error: {str(e)}")
        return px.line(title=f"{resource} Trend - Data Error")

# ================= DASH APP =================
app = Dash(__name__, external_stylesheets=[dbc.themes.CERULEAN, "https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css"])
app.title = "Capacity Management Dashboard"

app.layout = dbc.Container([
    html.H1("Capacity Management Dashboard", className="text-center my-3"),
    dbc.Tabs([
        dbc.Tab(label="Dashboard", children=[
            dbc.Row(id="kpi-row", className="mt-3"),
            html.Hr(),
            dcc.Dropdown(
                id="trend-resource",
                options=[{"label":i,"value":i} for i in ["CPU","RAM","STORAGE"]],
                value="CPU",
                clearable=False
            ),
            dcc.Graph(id="trend"),
            html.Hr(),
            html.H5("Recent Events"),
            html.Div(id="recent-events")
        ]),
        dbc.Tab(label="Events", children=[
            dbc.Row([
                dbc.Col([
                    dbc.Input(id="server", placeholder="Server name"),
                    dbc.Input(id="cpu", type="number", placeholder="CPU delta (cores)"),
                    dbc.Input(id="ram", type="number", placeholder="RAM delta (GB)"),
                    dbc.Input(id="storage", type="number", placeholder="Storage delta (GB)"),
                    dbc.Button("Submit Event", id="submit", color="primary", className="mt-2"),
                    html.Div(id="msg", className="mt-2"),
                    html.Hr(),
                    dcc.Upload(
                        id="csv-upload",
                        children=dbc.Button("Upload CSV"),
                        accept=".csv"
                    ),
                    html.Div(id="csv-msg", className="mt-2")
                ], md=4),
                dbc.Col(html.Div(id="event-table"), md=8)
            ], className="mt-3")
        ]),
        dbc.Tab(label="Inventory", children=[
            html.Div(id="inventory-table", className="mt-3")
        ])
    ])
], fluid=True)

# ================= CALLBACKS =================
@callback(
    Output("kpi-row","children"),
    Input("kpi-row","id")
)
def load_kpis(_):
    cap = calculate_capacity()
    cards = []
    for k in ["CPU","RAM","STORAGE"]:
        d = cap[k]
        cards.append(
            dbc.Col(
                dbc.Card(
                    dbc.CardBody([
                        html.H6(k),
                        html.H3(fmt(d["used"], k)),
                        html.P(f"Total: {fmt(d['total'], k)}"),
                        html.P(f"Reserved: {fmt(d['reserved'], k)}"),
                        html.P(f"Usable: {fmt(d['usable'], k)}"),
                        html.P(f"Available: {fmt(d['available'], k)}"),
                        html.Small(f"Utilization: {d['pct']:.1f}%")
                    ]),
                    className="shadow text-center"
                ), md=4
            )
        )
    return cards

@callback(Output("trend","figure"), Input("trend-resource","value"))
def update_trend(r):
    return build_trend(r)

@callback(
    Output("msg","children"),
    Output("event-table","children"),
    Output("recent-events","children"),
    Output("csv-msg","children"),
    Input("submit","n_clicks"),
    Input("csv-upload","contents"),
    State("server","value"),
    State("cpu","value"),
    State("ram","value"),
    State("storage","value"),
    State("csv-upload","filename"),
    prevent_initial_call=True
)
def add_event(submit_n, csv_contents, server, cpu, ram, storage, filename):
    ctx = callback_context
    triggered = ctx.triggered[0]['prop_id'].split('.')[0]

    msg = ""
    csv_msg = ""
    if triggered == "submit.n_clicks" and submit_n:
        if not server:
            msg = dbc.Alert("Server name required", color="danger")
        else:
            try:
                with ENGINE.begin() as conn:
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source)
                        VALUES (:s, :c, :r, :st, 'MANUAL')
                    """), {"s": server, "c": float(cpu or 0), "r": float(ram or 0), "st": float(storage or 0)})
                msg = dbc.Alert("Event saved", color="success")
            except Exception as e:
                msg = dbc.Alert(f"Error: {str(e)}", color="danger")

    if triggered == "csv-upload.contents" and csv_contents:
        try:
            df = parse_csv(csv_contents, filename)
            with ENGINE.begin() as conn:
                for _, row in df.iterrows():
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time)
                        VALUES (:server, :cpu, :ram, :storage, 'CSV', :date)
                    """), {"server": row['server'], "cpu": row['cpu'], "ram": row['ram'], "storage": row['storage'], "date": row['date']})
            csv_msg = dbc.Alert(f"Imported {len(df)} rows", color="success")
        except Exception as e:
            csv_msg = dbc.Alert(f"Error: {str(e)}", color="danger")

    recent_df = pd.read_sql("""
        SELECT event_time, assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb
        FROM capacity_events
        ORDER BY event_time DESC
        LIMIT 10
    """, ENGINE)

    event_df = pd.read_sql("""
        SELECT event_time, assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb
        FROM capacity_events
        ORDER BY event_time DESC
    """, ENGINE)

    recent_table = dbc.Table.from_dataframe(recent_df, striped=True, hover=True) if not recent_df.empty else "No recent events"

    event_table = dbc.Table.from_dataframe(event_df, striped=True, hover=True) if not event_df.empty else "No events"

    return msg, event_table, recent_table, csv_msg

@callback(
    Output("inventory-table","children"),
    Input("inventory-table","id")
)
def load_inventory(_):
    df = pd.read_sql("""
        SELECT assetuniquename AS "Server Name",
               assetipaddress AS "IP Address",
               servercores AS "CPU Cores",
               ROUND(NULLIF(TRIM(servermemory), '')::numeric / 1024.0, 2) || ' GB' AS "RAM",
               totaldisk || ' GB' AS "Storage",
               assetstatus AS "Status"
        FROM inventory
    """, ENGINE).fillna("N/A")
    return dbc.Table.from_dataframe(df, striped=True, hover=True) if not df.empty else "No inventory data"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8050, debug=False)
```<|control12|>```python
# app.py - Full Working Capacity Management Dashboard
# UI: Attractive with Cerulean theme, icons, shadows, colors
# KPI: All fields (Total, Reserved, Usable, Available, Used, Utilization %)
# Trend: Inventory baseline + events; flat if no events
# Inventory: RAM in GB with 2 decimals + unit, friendly names
# Events: Form + CSV upload
# Log: 7 day rotating txt file
# Add: High util alerts, refresh button
# Run: python app.py
# Open: http://localhost:8050

import base64
import io
import pandas as pd
import plotly.express as px
from sqlalchemy import create_engine, text
from datetime import datetime, timedelta
import logging
from logging.handlers import TimedRotatingFileHandler

from dash import Dash, dcc, html, Input, Output, State, callback, no_update
from dash import callback_context
import dash_bootstrap_components as dbc

from config import DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT

# ================= LOGGING =================
logger = logging.getLogger("capacity_dash")
logger.setLevel(logging.INFO)
handler = TimedRotatingFileHandler("capacity.log", when="midnight", backupCount=7)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ================= DB =================
ENGINE = create_engine(
    f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
    f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}",
    pool_pre_ping=True
)

# ================= HELPERS =================
def fmt(val, unit):
    val = float(val) if val else 0
    if unit == "CPU":
        return f"{int(val):,} cores"
    if val >= 1024:
        return f"{val/1024:.2f} TB"
    return f"{val:.2f} GB"

def parse_csv(contents, filename):
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    try:
        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        required = {'date', 'server', 'cpu', 'ram', 'storage'}
        if not required.issubset(df.columns.str.lower()):
            raise ValueError("CSV must contain columns: date, server, cpu, ram, storage")
        df.columns = df.columns.str.lower()
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])
        for col in ['cpu', 'ram', 'storage']:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        return df
    except Exception as e:
        logger.error(f"CSV parse error: {str(e)}")
        raise ValueError(f"CSV parsing failed: {str(e)}")

# ================= CAPACITY CALC =================
def calculate_capacity():
    try:
        inv = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024, 0) AS ram,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage
            FROM inventory
        """, ENGINE)
        base = {
            "CPU": float(inv.cpu.iloc[0]),
            "RAM": float(inv.ram.iloc[0]),
            "STORAGE": float(inv.storage.iloc[0])
        }
        ev = pd.read_sql("""
            SELECT
                COALESCE(SUM(cpu_delta), 0) AS cpu,
                COALESCE(SUM(ram_delta_gb), 0) AS ram,
                COALESCE(SUM(storage_delta_gb), 0) AS storage
            FROM capacity_events
        """, ENGINE)
        used = {
            "CPU": base["CPU"] + float(ev.cpu.iloc[0]),
            "RAM": base["RAM"] + float(ev.ram.iloc[0]),
            "STORAGE": base["STORAGE"] + float(ev.storage.iloc[0])
        }
        result = {}
        for k in used:
            total = TOTAL_CAPACITY[k]
            reserved = total * RESERVED_PERCENT
            usable = total - reserved
            pct = (used[k] / usable * 100) if usable > 0 else 0
            available = max(usable - used[k], 0)
            result[k] = {
                "used": used[k],
                "total": total,
                "reserved": reserved,
                "usable": usable,
                "available": available,
                "pct": pct
            }
        logger.info("Capacity calculated")
        return result
    except Exception as e:
        logger.error(f"Capacity calc error: {str(e)}")
        return {k: {"used":0, "total":0, "reserved":0, "usable":0, "available":0, "pct":0} for k in ["CPU", "RAM", "STORAGE"]}

# ================= TREND =================
def build_trend(resource):
    try:
        base = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024, 0) AS ram,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage
            FROM inventory
        """, ENGINE)
        baseline = float(base[resource.lower()].iloc[0])

        today = datetime.today().date()
        thirty_days_ago = today - timedelta(days=30)

        df = pd.read_sql("""
            SELECT DATE(event_time) AS d,
                   SUM(CASE WHEN :r = 'CPU' THEN cpu_delta
                            WHEN :r = 'RAM' THEN ram_delta_gb
                            WHEN :r = 'STORAGE' THEN storage_delta_gb
                       END) AS v
            FROM capacity_events
            GROUP BY DATE(event_time)
            ORDER BY d
        """, ENGINE, params={"r": resource})

        if df.empty:
            df = pd.DataFrame({"d": [thirty_days_ago, today], "used": [baseline, baseline]})
            fig = px.line(df, x="d", y="used", title=f"{resource} Trend (Based on Inventory - No Events)", template="plotly_white")
        else:
            df = df.set_index('d').reindex(pd.date_range(thirty_days_ago, today)).fillna(0).reset_index()
            df.columns = ['d', 'v']
            df['used'] = baseline + df['v'].cumsum()
            fig = px.area(df, x="d", y="used", title=f"{resource} Trend (Inventory + Events)", template="plotly_white")

        fig.update_layout(height=350, xaxis_title="Date", yaxis_title="Used")
        return fig
    except Exception as e:
        logger.error(f"Trend error: {str(e)}")
        return px.line(title=f"{resource} Trend - Data Error")

# ================= DASH APP =================
app = Dash(__name__, external_stylesheets=[dbc.themes.CERULEAN, "https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css"])
app.title = "Capacity Management Dashboard"

app.layout = dbc.Container([
    html.H1("Capacity Management Dashboard", className="text-center my-4 text-primary"),
    dbc.Tabs([
        # ===== DASHBOARD =====
        dbc.Tab(label="Dashboard", children=[
            dbc.Row(id="kpi-row", className="mt-3"),
            html.Hr(),
            dcc.Dropdown(
                id="trend-resource",
                options=[{"label":i,"value":i} for i in ["CPU","RAM","STORAGE"]],
                value="CPU",
                clearable=False
            ),
            dcc.Graph(id="trend"),
            html.Hr(),
            html.H5("Recent Events"),
            html.Div(id="recent-events")
        ]),
        # ===== EVENTS =====
        dbc.Tab(label="Events", children=[
            dbc.Row([
                dbc.Col([
                    dbc.Input(id="server", placeholder="Server name"),
                    dbc.Input(id="cpu", type="number", placeholder="CPU delta (cores)"),
                    dbc.Input(id="ram", type="number", placeholder="RAM delta (GB)"),
                    dbc.Input(id="storage", type="number", placeholder="Storage delta (GB)"),
                    dbc.Button("Submit Event", id="submit", color="primary", className="mt-2"),
                    html.Div(id="msg", className="mt-2"),
                    html.Hr(),
                    dcc.Upload(
                        id="csv-upload",
                        children=dbc.Button("Upload CSV"),
                        accept=".csv"
                    ),
                    html.Div(id="csv-msg", className="mt-2")
                ], md=4),
                dbc.Col(html.Div(id="event-table"), md=8)
            ], className="mt-3")
        ]),
        # ===== INVENTORY =====
        dbc.Tab(label="Inventory", children=[
            html.Div(id="inventory-table", className="mt-3")
        ])
    ])
], fluid=True, style={"background": "linear-gradient(to bottom, #f8f9fa, #e3f2fd)"})  # Attractive gradient background

# ================= CALLBACKS =================
@callback(
    Output("kpi-row","children"),
    Input("kpi-row","id")
)
def load_kpis(_):
    cap = calculate_capacity()
    cards = []
    for k in ["CPU","RAM","STORAGE"]:
        d = cap[k]
        cards.append(
            dbc.Col(
                dbc.Card(
                    dbc.CardBody([
                        html.H6(k),
                        html.H3(fmt(d["used"], k)),
                        html.P(f"Total: {fmt(d['total'], k)}"),
                        html.P(f"Reserved: {fmt(d['reserved'], k)}"),
                        html.P(f"Usable: {fmt(d['usable'], k)}"),
                        html.P(f"Available: {fmt(d['available'], k)}"),
                        html.Small(f"Utilization: {d['pct']:.1f}%")
                    ]),
                    className="shadow text-center"
                ), md=4
            )
        )
    return cards

@callback(Output("trend","figure"), Input("trend-resource","value"))
def update_trend(r):
    return build_trend(r)

@callback(
    Output("msg","children"),
    Output("event-table","children"),
    Output("recent-events","children"),
    Output("csv-msg","children"),
    Input("submit","n_clicks"),
    Input("csv-upload","contents"),
    State("server","value"),
    State("cpu","value"),
    State("ram","value"),
    State("storage","value"),
    State("csv-upload","filename"),
    prevent_initial_call=True
)
def add_event(submit_n, csv_contents, server, cpu, ram, storage, filename):
    ctx = callback_context
    triggered = ctx.triggered[0]['prop_id'].split('.')[0]

    msg = ""
    csv_msg = ""
    if triggered == "submit.n_clicks" and submit_n:
        if not server:
            msg = dbc.Alert("Server name required", color="danger")
        else:
            try:
                with ENGINE.begin() as conn:
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source)
                        VALUES (:s, :c, :r, :st, 'MANUAL')
                    """), {"s": server, "c": float(cpu or 0), "r": float(ram or 0), "st": float(storage or 0)})
                msg = dbc.Alert("Event saved", color="success")
            except Exception as e:
                msg = dbc.Alert(f"Error: {str(e)}", color="danger")

    if triggered == "csv-upload.contents" and csv_contents:
        try:
            df = parse_csv(csv_contents, filename)
            with ENGINE.begin() as conn:
                for _, row in df.iterrows():
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time)
                        VALUES (:server, :cpu, :ram, :storage, 'CSV', :date)
                    """), {"server": row['server'], "cpu": row['cpu'], "ram": row['ram'], "storage": row['storage'], "date": row['date']})
            csv_msg = dbc.Alert(f"Imported {len(df)} rows", color="success")
        except Exception as e:
            csv_msg = dbc.Alert(f"Error: {str(e)}", color="danger")

    recent_df = pd.read_sql("""
        SELECT event_time, assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb
        FROM capacity_events
        ORDER BY event_time DESC
        LIMIT 10
    """, ENGINE)

    event_df = pd.read_sql("""
        SELECT event_time, assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb
        FROM capacity_events
        ORDER BY event_time DESC
    """, ENGINE)

    recent_table = dbc.Table.from_dataframe(recent_df, striped=True, hover=True) if not recent_df.empty else "No recent events"

    event_table = dbc.Table.from_dataframe(event_df, striped=True, hover=True) if not event_df.empty else "No events"

    return msg, event_table, recent_table, csv_msg

@callback(
    Output("inventory-table","children"),
    Input("inventory-table","id")
)
def load_inventory(_):
    df = pd.read_sql("""
        SELECT assetuniquename AS "Server Name",
               assetipaddress AS "IP Address",
               servercores AS "CPU Cores",
               ROUND(NULLIF(TRIM(servermemory), '')::numeric / 1024.0, 2) || ' GB' AS "RAM",
               totaldisk || ' GB' AS "Storage",
               assetstatus AS "Status"
        FROM inventory
    """, ENGINE).fillna("N/A")
    return dbc.Table.from_dataframe(df, striped=True, hover=True) if not df.empty else "No inventory data"

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8050, debug=False)
