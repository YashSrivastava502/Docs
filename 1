import paramiko
import pandas as pd
import psycopg2
import smtplib
from io import StringIO
from email.mime.text import MIMEText

# ========================
# SFTP CONFIG
# ========================
SFTP_HOST = "your_sftp_host"
SFTP_PORT = 22
SFTP_USER = "your_sftp_user"
SFTP_PASS = "your_sftp_password"

REMOTE_DIR = "/Network_devices_Backup/Global-Inventory"
REMOTE_FILE = "Global-SystemInventory.csv"

# ========================
# POSTGRES CONFIG
# ========================
PG_HOST = "10.7.32.181"
PG_PORT = 5432
PG_USER = "postgres"
PG_PASS = "mc6Qld8x0910"
TARGET_DB = "GlobalInventory"

# ========================
# SMTP CONFIG (NO AUTH)
# ========================
SMTP_SERVER = "your.smtp.server"
SMTP_PORT = 25
MAIL_FROM = "inventory-report@company.com"
MAIL_TO = ["ops@company.com"]

# ========================
# REQUIRED CSV COLUMNS
# ========================
COLUMNS = [
    "AssetUniqueName",
    "AssetIPAddress",
    "AssetStatus",
    "AssetLocation",
    "AssetType",
    "AssetsApplication/Owner",
    "CostCenter",
    "Environment",
    "ServerDomain",
    "ServerOS",
    "ServerCores",
    "ServerMemory",
    "TotalDisk",
    "ClusterName",
    "HostName"
]

# ========================
# FETCH CSV FROM SFTP
# ========================
def fetch_csv():
    transport = paramiko.Transport((SFTP_HOST, SFTP_PORT))
    transport.connect(username=SFTP_USER, password=SFTP_PASS)
    sftp = paramiko.SFTPClient.from_transport(transport)

    with sftp.open(f"{REMOTE_DIR}/{REMOTE_FILE}", "r") as f:
        data = f.read().decode("utf-8")

    sftp.close()
    transport.close()
    return data

# ========================
# CREATE DATABASE IF NOT EXISTS
# ========================
def ensure_database():
    conn = psycopg2.connect(
        host=PG_HOST,
        port=PG_PORT,
        user=PG_USER,
        password=PG_PASS,
        dbname="postgres"
    )
    conn.autocommit = True
    cur = conn.cursor()
    cur.execute("SELECT 1 FROM pg_database WHERE datname=%s", (TARGET_DB,))
    if not cur.fetchone():
        cur.execute(f'CREATE DATABASE "{TARGET_DB}"')
    cur.close()
    conn.close()

# ========================
# CONNECT TARGET DB
# ========================
def connect_target_db():
    return psycopg2.connect(
        host=PG_HOST,
        port=PG_PORT,
        user=PG_USER,
        password=PG_PASS,
        dbname=TARGET_DB
    )

# ========================
# CREATE TABLES
# ========================
def create_tables(conn):
    cur = conn.cursor()

    cur.execute("""
    CREATE TABLE IF NOT EXISTS inventory (
        AssetUniqueName TEXT PRIMARY KEY,
        AssetIPAddress TEXT,
        AssetStatus TEXT,
        AssetLocation TEXT,
        AssetType TEXT,
        AssetsApplicationOwner TEXT,
        CostCenter TEXT,
        Environment TEXT,
        ServerDomain TEXT,
        ServerOS TEXT,
        ServerCores TEXT,
        ServerMemory TEXT,
        TotalDisk TEXT,
        ClusterName TEXT,
        HostName TEXT
    )
    """)

    cur.execute("""
    CREATE TABLE IF NOT EXISTS inventory_change_audit (
        id BIGSERIAL PRIMARY KEY,
        asset_unique_name TEXT,
        column_name TEXT,
        old_value TEXT,
        new_value TEXT,
        change_type TEXT,
        changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
    """)

    conn.commit()
    cur.close()

# ========================
# FETCH EXISTING DATA
# ========================
def fetch_existing(conn):
    return pd.read_sql("SELECT * FROM inventory", conn)

# ========================
# UPSERT + AUDIT
# ========================
def upsert_and_audit(conn, df_new, df_old):
    cur = conn.cursor()
    changes = []

    if not df_old.empty:
        df_old = df_old.set_index("AssetUniqueName")

    for _, row in df_new.iterrows():
        asset = row["AssetUniqueName"]

        if not df_old.empty and asset in df_old.index:
            old_row = df_old.loc[asset]
            for col in df_new.columns:
                old_val = str(old_row[col])
                new_val = str(row[col])
                if old_val != new_val:
                    cur.execute("""
                        INSERT INTO inventory_change_audit
                        (asset_unique_name, column_name, old_value, new_value, change_type)
                        VALUES (%s,%s,%s,%s,'UPDATE')
                    """, (asset, col, old_val, new_val))
                    changes.append(f"{asset} | {col} | {old_val} -> {new_val}")
        else:
            cur.execute("""
                INSERT INTO inventory_change_audit
                (asset_unique_name, column_name, old_value, new_value, change_type)
                VALUES (%s,'*',NULL,'NEW ROW','INSERT')
            """, (asset,))
            changes.append(f"{asset} | NEW ROW")

        cur.execute("""
        INSERT INTO inventory VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
        ON CONFLICT (AssetUniqueName) DO UPDATE SET
        AssetIPAddress=EXCLUDED.AssetIPAddress,
        AssetStatus=EXCLUDED.AssetStatus,
        AssetLocation=EXCLUDED.AssetLocation,
        AssetType=EXCLUDED.AssetType,
        AssetsApplicationOwner=EXCLUDED.AssetsApplicationOwner,
        CostCenter=EXCLUDED.CostCenter,
        Environment=EXCLUDED.Environment,
        ServerDomain=EXCLUDED.ServerDomain,
        ServerOS=EXCLUDED.ServerOS,
        ServerCores=EXCLUDED.ServerCores,
        ServerMemory=EXCLUDED.ServerMemory,
        TotalDisk=EXCLUDED.TotalDisk,
        ClusterName=EXCLUDED.ClusterName,
        HostName=EXCLUDED.HostName
        """, tuple(row))

    conn.commit()
    cur.close()
    return changes

# ========================
# SEND EMAIL
# ========================
def send_mail(changes):
    if not changes:
        return

    body = "Global Inventory Changes:\n\n" + "\n".join(changes)
    msg = MIMEText(body)
    msg["Subject"] = "Weekly Global Inventory Change Report"
    msg["From"] = MAIL_FROM
    msg["To"] = ", ".join(MAIL_TO)

    smtp = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
    smtp.sendmail(MAIL_FROM, MAIL_TO, msg.as_string())
    smtp.quit()

# ========================
# MAIN
# ========================
def main():
    csv_data = fetch_csv()
    df = pd.read_csv(StringIO(csv_data))[COLUMNS]

    # Rename DB-unsafe column
    df = df.rename(columns={"AssetsApplication/Owner": "AssetsApplicationOwner"})

    # FORCE ALL VALUES TO STRING (CRITICAL)
    for col in df.columns:
        df[col] = df[col].astype(str)

    ensure_database()
    conn = connect_target_db()
    create_tables(conn)

    df_old = fetch_existing(conn)
    changes = upsert_and_audit(conn, df, df_old)

    send_mail(changes)
    conn.close()

    print("âœ… ETL completed successfully")

if __name__ == "__main__":
    main()
