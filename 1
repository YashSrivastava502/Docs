# mian.py - Capacity Management Dashboard (Enhanced UI, fixed KPIs, improved trends)
# - Improvements:
#   - Compact, responsive Events layout (instructions / form / recent events on one row)
#   - Stronger RAM-event unit detection for correct KPI calculations
#   - Better-looking trend charts (baseline + cumulative used line, clearer colors)
#   - Distinct background and text colors, improved card styling
#   - Keep event RAM stored as MB (conversion on insert), but robustly handle historical data
# Notes:
#   - Ensure config.py provides DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT
#   - Required packages: dash, dash-bootstrap-components, pandas, sqlalchemy, psycopg2-binary, plotly

import base64
import io
from datetime import datetime, timedelta

import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from sqlalchemy import create_engine, text

import logging
from logging.handlers import TimedRotatingFileHandler

from dash import Dash, dcc, html, Input, Output, State, callback, callback_context, no_update
import dash_bootstrap_components as dbc

# Config (user must provide)
from config import DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT

# ================= LOGGING =================
logger = logging.getLogger("capacity_dashboard")
logger.setLevel(logging.INFO)
handler = TimedRotatingFileHandler("capacity.log", when="midnight", backupCount=7)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ================= DB CONNECTION =================
ENGINE = create_engine(
    f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
    f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}",
    pool_pre_ping=True
)

# ================= HELPERS =================
def fmt(val, unit):
    """Format numeric value with unit. CPU is cores (integer), RAM/STORAGE shown in GB or TB."""
    try:
        val = float(val) if val is not None else 0.0
    except Exception:
        val = 0.0
    if unit == "CPU":
        return f"{int(round(val)):,} cores"
    if val >= 1024:
        return f"{val/1024:.2f} TB"
    return f"{val:.2f} GB"

def parse_csv(contents, filename):
    """
    Parse CSV uploaded via dcc.Upload.
    Required columns (case-insensitive): date, server, cpu, ram, storage
      - ram: GB (user-friendly); converted to MB on insert
      - storage: GB
    Returns DataFrame with columns: date, server, cpu, ram_gb, storage_gb
    """
    if not contents:
        raise ValueError("No file contents provided")
    content_type, content_string = contents.split(',')
    decoded = base64.b64decode(content_string)
    try:
        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        lc = [c.lower() for c in df.columns]
        required = {'date', 'server', 'cpu', 'ram', 'storage'}
        if not required.issubset(set(lc)):
            raise ValueError("CSV must contain columns: date, server, cpu, ram, storage")
        mapping = {orig: orig.lower() for orig in df.columns}
        df = df.rename(columns=mapping)
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])
        df['server'] = df['server'].astype(str)
        for col in ['cpu', 'ram', 'storage']:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        df = df[['date', 'server', 'cpu', 'ram', 'storage']].rename(columns={'ram': 'ram_gb', 'storage': 'storage_gb'})
        return df
    except Exception as e:
        logger.exception("Failed parsing CSV")
        raise ValueError(f"CSV parsing failed: {e}")

# ================= UNIT NORMALIZATION HELPERS =================
def detect_ram_events_unit_and_convert_to_gb(ram_sum_raw, ram_max_raw, baseline_gb):
    """
    Decide if stored event RAM delta values are in MB or GB.
    Heuristic:
      - If max absolute event magnitude >> baseline (x10) OR max > 1024*5,
        treat stored values as MB and convert to GB by dividing sums by 1024.
      - Else treat as GB.
    """
    try:
        ram_sum = float(ram_sum_raw)
        ram_max = float(ram_max_raw)
    except Exception:
        return 0.0

    if baseline_gb is None or baseline_gb <= 0:
        # fallback: if max is very large (>5 TB in GB terms) probably MB
        if abs(ram_max) > 1024 * 5:
            return ram_sum / 1024.0
        return ram_sum

    if abs(ram_max) > abs(baseline_gb) * 10 or abs(ram_max) > 1024 * 5:
        return ram_sum / 1024.0

    return ram_sum

# ================= CAPACITY CALCULATION =================
def calculate_capacity():
    try:
        inv = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024.0, 0) AS ram,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage
            FROM inventory
        """, ENGINE)

        baseline_cpu = float(inv['cpu'].iloc[0])
        baseline_ram_gb = float(inv['ram'].iloc[0])   # inventory servermemory in MB -> /1024 => GB
        baseline_storage = float(inv['storage'].iloc[0])

        # Aggregate events and pull max for unit detection
        ev_agg = pd.read_sql("""
            SELECT
                COALESCE(SUM(cpu_delta), 0) AS cpu_sum,
                COALESCE(SUM(ram_delta_gb), 0) AS ram_sum_raw,
                COALESCE(MAX(ABS(ram_delta_gb)), 0) AS ram_max_raw,
                COALESCE(SUM(storage_delta_gb), 0) AS storage_sum
            FROM capacity_events
        """, ENGINE)

        cpu_sum = float(ev_agg['cpu_sum'].iloc[0])
        ram_sum_raw = float(ev_agg['ram_sum_raw'].iloc[0])
        ram_max_raw = float(ev_agg['ram_max_raw'].iloc[0])
        storage_sum = float(ev_agg['storage_sum'].iloc[0])

        # Decide unit and convert ram events sum to GB
        ram_sum_gb = detect_ram_events_unit_and_convert_to_gb(ram_sum_raw, ram_max_raw, baseline_ram_gb)

        used = {
            "CPU": baseline_cpu + cpu_sum,
            "RAM": baseline_ram_gb + ram_sum_gb,
            "STORAGE": baseline_storage + storage_sum
        }

        result = {}
        for k in used:
            total = TOTAL_CAPACITY.get(k, 0)
            reserved = total * RESERVED_PERCENT
            usable = max(total - reserved, 0)
            used_k = max(used[k], 0)
            pct = (used_k / usable * 100) if usable > 0 else 0
            available = max(usable - used_k, 0)
            result[k] = {
                "used": used_k,
                "total": total,
                "reserved": reserved,
                "usable": usable,
                "available": available,
                "pct": pct
            }
        logger.info("Capacity calculated: %s", result)
        return result
    except Exception as e:
        logger.exception("Capacity calculation failed")
        return {
            "CPU": {"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0},
            "RAM": {"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0},
            "STORAGE": {"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0}
        }

# ================= TREND FUNCTION (nicer visuals) =================
def build_trend(resource):
    """
    Build an attractive trend chart:
      - Baseline (inventory) shown as a dotted horizontal line
      - Cumulative used plotted as a filled line
      - Usable total drawn as a dashed line (so users see headroom)
      - Clear y-axis label with units
    """
    try:
        # Baseline read
        base = pd.read_sql("""
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024.0, 0) AS ram,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage
            FROM inventory
        """, ENGINE)
        baseline = float(base[resource.lower()].iloc[0])

        # Total usable (for dashed target line)
        total = TOTAL_CAPACITY.get(resource, 0)
        reserved = total * RESERVED_PERCENT
        usable_total = max(total - reserved, 0)

        today = datetime.today().date()
        thirty_days_ago = today - timedelta(days=30)

        df = pd.read_sql(text("""
            SELECT DATE(event_time) AS d,
                   SUM(
                       CASE
                           WHEN :r = 'CPU' THEN COALESCE(cpu_delta, 0)
                           WHEN :r = 'RAM' THEN COALESCE(ram_delta_gb, 0)
                           WHEN :r = 'STORAGE' THEN COALESCE(storage_delta_gb, 0)
                           ELSE 0
                       END
                   ) AS v
            FROM capacity_events
            WHERE event_time >= :start_date
            GROUP BY DATE(event_time)
            ORDER BY d
        """), ENGINE, params={"r": resource, "start_date": thirty_days_ago})

        date_range = pd.date_range(thirty_days_ago, today)
        if df.empty:
            df = pd.DataFrame({"d": date_range, "v": 0})
        else:
            df = df.set_index('d').reindex(date_range).fillna(0).reset_index()
            df.columns = ['d', 'v']

        # RAM unit detection for trend data: same heuristic as capacity calc
        if resource == "RAM":
            max_v = df['v'].abs().max()
            if max_v > (abs(baseline) * 10 if baseline > 0 else 1024 * 5):
                df['v'] = df['v'] / 1024.0

        df['used'] = baseline + df['v'].cumsum()

        # Build figure with plotly.graph_objects for custom styling
        fig = go.Figure()

        # Filled cumulative used
        fig.add_trace(go.Scatter(
            x=df['d'],
            y=df['used'],
            mode='lines',
            line=dict(color='#0d6efd', width=3),
            fill='tozeroy',
            name='Used'
        ))

        # Baseline dotted line
        fig.add_trace(go.Scatter(
            x=[df['d'].iloc[0], df['d'].iloc[-1]],
            y=[baseline, baseline],
            mode='lines',
            line=dict(color='rgba(13,110,253,0.6)', width=1, dash='dot'),
            name='Baseline'
        ))

        # Usable total dashed line (if >0)
        if usable_total > 0:
            fig.add_trace(go.Scatter(
                x=[df['d'].iloc[0], df['d'].iloc[-1]],
                y=[usable_total, usable_total],
                mode='lines',
                line=dict(color='rgba(220,53,69,0.6)', width=1, dash='dash'),
                name='Usable'
            ))

        y_label = "Used (cores)" if resource == "CPU" else "Used (GB)"
        fig.update_layout(
            title=f"{resource} Usage - Last 30 Days",
            template="plotly_white",
            height=360,
            xaxis_title="Date",
            yaxis_title=y_label,
            legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
            margin=dict(l=40, r=20, t=50, b=30)
        )
        return fig
    except Exception as e:
        logger.exception("Trend build failed")
        return px.area(title=f"{resource} Trend - No data")

# ================= DASH APP & LAYOUT =================
app = Dash(__name__, external_stylesheets=[dbc.themes.LITERA])
app.title = "Capacity Management Dashboard"

# Navbar with compact controls
navbar = dbc.Navbar(
    dbc.Container([
        dbc.Row([
            dbc.Col(html.H5("Capacity Dashboard", className="mb-0 text-white"), align="center")
        ]),
        dbc.Row([
            dbc.Col(dbc.Button("Refresh", id="refresh", color="light", className="me-2")),
            # NOTE: Additional admin controls could go here (migration button, etc.)
        ], align="center", className="g-0")
    ]),
    color="#0b5ed7",  # strong blue header
    dark=True,
    className="mb-3 shadow-sm",
    sticky="top"
)

# Instructions (compact)
events_instructions = dbc.Card(
    dbc.CardBody([
        html.H6("How to add events (manual)", className="mb-2"),
        html.Ul([
            html.Li("Server: unique server name (required) — best to match inventory."),
            html.Li("CPU Δ: number of cores to add (+) or remove (−). Leave blank or 0 if none."),
            html.Li("RAM Δ: enter change in GB (e.g., 8 or −4). App saves as MB for DB consistency."),
            html.Li("Storage Δ: enter change in GB (e.g., 100 or −50). Saved in GB."),
            html.Li("At least one of CPU, RAM, or Storage must be a non-zero value."),
        ], style={"fontSize": "0.9rem"}),
        html.H6("CSV Upload", className="mt-3"),
        html.P("CSV headers (case-insensitive): date,server,cpu,ram,storage", style={"fontSize": "0.9rem", "marginBottom":"0.25rem"}),
        html.Pre("Example:\n2026-01-10,web-01,2,8,100\n2026-01-11,db-01,0,16,500", style={"whiteSpace": "pre-wrap", "fontSize":"0.8rem"})
    ]),
    className="mb-2"
)

# App layout
app.layout = dbc.Container([
    navbar,
    html.Div([
        html.H1("Capacity Management Dashboard", className="display-6", style={"color":"#0b5ed7"}),
        html.P("Overview of current capacity, trends and events", style={"color":"#495057"})
    ], className="mb-3"),
    dcc.Interval(id="interval", interval=5*60*1000, n_intervals=0),  # 5 minutes

    dbc.Tabs([
        # Dashboard tab
        dbc.Tab(label="Dashboard", tab_style={"fontWeight":"700"}, children=[
            html.H5("Current Capacity Overview", className="mt-4 mb-3"),
            dbc.Row(id="kpi-row", className="g-4 mb-4"),
            html.H5("30-Day Usage Trends", className="mt-4 mb-3"),
            dbc.Row([
                dbc.Col(dcc.Graph(id="cpu-trend"), md=4),
                dbc.Col(dcc.Graph(id="ram-trend"), md=4),
                dbc.Col(dcc.Graph(id="storage-trend"), md=4),
            ]),
            html.Div(id="alerts", className="mt-3")
        ]),

        # Events tab: compact single-row layout (instructions / form / recent)
        dbc.Tab(label="Events", tab_style={"fontWeight":"700"}, children=[
            dbc.Row([
                dbc.Col(events_instructions, md=3),

                dbc.Col(
                    dbc.Card(
                        dbc.CardBody([
                            html.H5("Add New Event", className="text-primary mb-3"),
                            dbc.Row([
                                dbc.Col(dbc.Input(id="server", placeholder="Server (required)"), md=12)
                            ], className="mb-2"),
                            dbc.Row([
                                dbc.Col(dbc.Input(id="cpu", type="number", placeholder="CPU Δ (cores)"), md=6),
                                dbc.Col(dbc.Input(id="ram", type="number", placeholder="RAM Δ (GB)"), md=6),
                            ], className="mb-2"),
                            dbc.Row([
                                dbc.Col(dbc.Input(id="storage", type="number", placeholder="Storage Δ (GB)"), md=12),
                            ], className="mb-3"),
                            dbc.Button("Submit Event", id="submit", color="primary", className="w-100"),
                            html.Div(id="msg", className="mt-3")
                        ]),
                        className="shadow-sm"
                    ), md=4
                ),

                dbc.Col(
                    dbc.Card(
                        dbc.CardBody([
                            html.H5("Recent Events (last 10)", className="mb-3 text-primary"),
                            html.Div(id="recent-events")
                        ])
                    ), md=5
                )
            ], className="mt-3")
        ]),

        # Inventory tab
        dbc.Tab(label="Inventory", tab_style={"fontWeight":"700"}, children=[
            html.H5("Server Inventory", className="mt-4 mb-3"),
            html.Div(id="inventory-table")
        ])
    ], className="mb-4")
], fluid=True, style={"background":"linear-gradient(to bottom, #f7fbff, #ffffff)", "minHeight":"100vh"})

# ================= CALLBACKS =================
@callback(
    [
        Output("kpi-row", "children"),
        Output("alerts", "children"),
        Output("cpu-trend", "figure"),
        Output("ram-trend", "figure"),
        Output("storage-trend", "figure"),
        Output("recent-events", "children"),
        Output("inventory-table", "children"),
        Output("msg", "children"),
        Output("csv-msg", "children")
    ],
    [
        Input("submit", "n_clicks"),
        Input("csv-upload", "contents"),
        Input("interval", "n_intervals"),
        Input("refresh", "n_clicks")
    ],
    [
        State("server", "value"),
        State("cpu", "value"),
        State("ram", "value"),
        State("storage", "value"),
        State("csv-upload", "filename")
    ],
    prevent_initial_call=False
)
def master_callback(submit_n, csv_contents, n_intervals, refresh_n, server, cpu, ram, storage, filename):
    ctx = callback_context
    triggered_prop = ctx.triggered[0]['prop_id'] if ctx.triggered else ""
    triggered_id = triggered_prop.split('.')[0] if triggered_prop else ""

    msg = no_update
    csv_msg = no_update
    refresh_needed = False

    # Manual event submit
    if triggered_id == "submit" and submit_n:
        if not server or str(server).strip() == "":
            msg = dbc.Alert("Server name required", color="danger")
        elif (cpu is None or float(cpu) == 0) and (ram is None or float(ram) == 0) and (storage is None or float(storage) == 0):
            msg = dbc.Alert("At least one non-zero delta (CPU, RAM, or Storage) must be provided", color="danger")
        else:
            try:
                ram_input_mb = 0.0
                if ram is not None:
                    ram_input_mb = float(ram) * 1024.0  # convert GB -> MB for DB storage
                with ENGINE.begin() as conn:
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time)
                        VALUES (:s, :c, :r, :st, 'MANUAL', now())
                    """), {"s": server, "c": float(cpu or 0), "r": ram_input_mb, "st": float(storage or 0)})
                msg = dbc.Alert("Event saved (RAM converted to MB for DB consistency)", color="success")
                refresh_needed = True
            except Exception as e:
                logger.exception("Failed to insert manual event")
                msg = dbc.Alert(f"Error saving event: {str(e)}", color="danger")

    # CSV upload handled similarly; convert RAM GB -> MB on insert
    if triggered_id == "csv-upload" and csv_contents:
        try:
            df = parse_csv(csv_contents, filename)
            with ENGINE.begin() as conn:
                for _, row in df.iterrows():
                    ram_input_mb = float(row['ram_gb']) * 1024.0
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time)
                        VALUES (:server, :cpu, :ram, :storage, 'CSV', :date)
                    """), {
                        "server": row['server'],
                        "cpu": float(row['cpu']),
                        "ram": ram_input_mb,
                        "storage": float(row['storage']),
                        "date": row['date']
                    })
            csv_msg = dbc.Alert(f"Imported {len(df)} rows (RAM converted GB→MB on save)", color="success")
            refresh_needed = True
        except Exception as e:
            logger.exception("CSV import failed")
            csv_msg = dbc.Alert(f"CSV error: {str(e)}", color="danger")

    # Refresh on interval, manual refresh, initial load, or after changes
    if refresh_needed or triggered_id in ("interval", "refresh") or triggered_id == "":
        cap = calculate_capacity()

        # KPI cards build: visually consistent and clearer
        kpi_cards = []
        alerts = []
        for k in ["CPU", "RAM", "STORAGE"]:
            d = cap[k]
            if d["pct"] > 100:
                color = "danger"
            elif d["pct"] > 90:
                color = "danger"
            elif d["pct"] > 80:
                color = "warning"
            else:
                color = "primary"

            icon_map = {"CPU":"bi-cpu", "RAM":"bi-memory", "STORAGE":"bi-hdd"}
            icon = icon_map.get(k, "bi-bar-chart")

            card = dbc.Card([
                dbc.CardBody([
                    html.Div([
                        html.Span(className=f"{icon} me-2 fs-4", style={"color":"#0d6efd"}),
                        html.H6(k, className="d-inline-block", style={"margin":"0", "verticalAlign":"middle"})
                    ], className="d-flex align-items-center mb-2"),
                    html.H3(fmt(d["used"], k), className="mb-1"),
                    html.Div([
                        html.Small(f"Total: {fmt(d['total'], k)}", className="me-3"),
                        html.Small(f"Reserved: {fmt(d['reserved'], k)}", className="me-3"),
                        html.Small(f"Usable: {fmt(d['usable'], k)}"),
                    ], className="d-flex flex-wrap mb-2"),
                    dbc.Progress(
                        value=min(d["pct"], 100),
                        color=color,
                        striped=True,
                        animated=d["pct"] > 90,
                        style={"height":"18px"}
                    ),
                    html.Div([
                        html.Small(f"Available: {fmt(d['available'], k)}"),
                        html.Span(f"{d['pct']:.1f}% Utilization", className="fw-bold ms-3")
                    ], className="mt-2 d-flex justify-content-between")
                ])
            ], className="shadow-sm")

            kpi_cards.append(dbc.Col(card, md=4))

            if d["pct"] > 90:
                alerts.append(dbc.Alert(f"High {k} utilization ({d['pct']:.1f}%) — consider action", color="warning", dismissable=True))

        # Trends
        cpu_trend = build_trend("CPU")
        ram_trend = build_trend("RAM")
        storage_trend = build_trend("STORAGE")

        # Recent events (last 10)
        recent_df = pd.read_sql("""
            SELECT event_time, assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb
            FROM capacity_events
            ORDER BY event_time DESC LIMIT 10
        """, ENGINE)
        if not recent_df.empty:
            def present_ram_val(v):
                try:
                    vv = float(v)
                except:
                    return v
                if abs(vv) > 1024 * 2:
                    return f"{vv/1024:.2f} GB"
                return f"{vv:.2f} GB"
            recent_df = recent_df.rename(columns={
                "event_time": "Event Time",
                "assetuniquename": "Server",
                "cpu_delta": "CPU Δ",
                "ram_delta_gb": "RAM Δ",
                "storage_delta_gb": "Storage Δ (GB)"
            })
            recent_df["RAM Δ"] = recent_df["RAM Δ"].apply(present_ram_val)
            recent_table = dbc.Table.from_dataframe(recent_df, striped=True, hover=True, bordered=True, responsive=True)
        else:
            recent_table = html.P("No recent events", className="text-center text-muted p-4")

        # Inventory table: units only in headers
        inv_df = pd.read_sql("""
            SELECT 
                assetuniquename AS "Server Name",
                assetipaddress AS "IP Address",
                servercores AS "CPU (cores)",
                ROUND(COALESCE(NULLIF(TRIM(servermemory), '')::numeric / 1024.0, 0), 2) AS "RAM (GB)",
                totaldisk AS "Storage (GB)",
                assetstatus AS "Status"
            FROM inventory
            ORDER BY assetuniquename
        """, ENGINE).fillna("N/A")

        if not inv_df.empty:
            inv_table = dbc.Table.from_dataframe(inv_df, striped=True, hover=True, bordered=True, responsive=True)
        else:
            inv_table = html.P("No inventory data", className="text-center text-muted p-4")

        return kpi_cards, alerts, cpu_trend, ram_trend, storage_trend, recent_table, inv_table, no_update, no_update

    # No change
    return no_update, no_update, no_update, no_update, no_update, no_update, no_update, no_update, no_update

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8050, debug=False)
