# mian.py - Capacity Management Dashboard (Final revisions)
# - Inventory filter per your SQL (assetstatus, assetlocation, assettype)
# - KPI: CPU in cores, RAM in GB, Storage in TB
# - Inventory: values shown with units in header only; RAM converted from MB -> GB
# - Events: users enter CPU (cores), RAM (GB) and Storage (GB). RAM is converted to MB on save.
# - Database stores: CPU cores, RAM in MB, Storage in GB (we handle conversions when reading/writing)
# - CSV upload instructions and example included
# - Improved UI layout and styling; compact Events area
# - Requires a config.py in same folder exporting DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT
#   TOTAL_CAPACITY keys: "CPU" (cores), "RAM" (GB), "STORAGE" (TB)
#   Example config.py:
#     DB_CONFIG = {"user":"user","password":"pw","host":"10.7.32.181","port":5432,"dbname":"GlobalInventory"}
#     TOTAL_CAPACITY = {"CPU": 6336, "RAM": 50688, "STORAGE": 762.03}
#     RESERVED_PERCENT = 0.30

import base64
import io
from datetime import datetime, timedelta

import pandas as pd
import plotly.graph_objects as go
from sqlalchemy import create_engine, text

import logging
from logging.handlers import TimedRotatingFileHandler

from dash import Dash, dcc, html, Input, Output, State, callback_context, no_update
import dash_bootstrap_components as dbc

# load config
from config import DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT

# ---------- Logging ----------
logger = logging.getLogger("capacity_dashboard")
logger.setLevel(logging.INFO)
handler = TimedRotatingFileHandler("capacity.log", when="midnight", backupCount=7)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ---------- DB ----------
ENGINE = create_engine(
    f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
    f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}",
    pool_pre_ping=True
)

# ---------- Inventory filters (per your FYI SQL) ----------
INVENTORY_STATUS = ("Running", "Running/Not in Production")
INVENTORY_LOCATION = "NJ Datacenter"
INVENTORY_TYPE = "Server/VM"  # exact string per your query

# ---------- Helpers ----------
def fmt_cpu(val):
    try:
        return f"{int(round(float(val))):,} cores"
    except Exception:
        return "0 cores"

def fmt_ram_gb(val):
    """Value is in GB. Show with 2 decimals and GB unit (KPI: always GB, not TB)."""
    try:
        v = float(val)
    except Exception:
        v = 0.0
    return f"{v:.2f} GB"

def fmt_storage_tb_from_gb(val):
    """Value passed in GB; convert to TB and format with 2 decimals."""
    try:
        gb = float(val)
    except Exception:
        gb = 0.0
    tb = gb / 1024.0
    return f"{tb:.2f} TB"

def parse_csv(contents, filename):
    """Parse uploaded CSV. Required headers: date,server,cpu,ram,storage (case-insensitive).
       ram and storage expected in GB; date parsed by pandas."""
    if not contents:
        raise ValueError("Empty upload")
    _, content_string = contents.split(',', 1)
    decoded = base64.b64decode(content_string)
    try:
        df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
        lc = [c.lower() for c in df.columns]
        required = {'date', 'server', 'cpu', 'ram', 'storage'}
        if not required.issubset(set(lc)):
            raise ValueError("CSV must contain headers: date,server,cpu,ram,storage")
        # normalize names
        mapping = {orig: orig.lower() for orig in df.columns}
        df = df.rename(columns=mapping)
        df['date'] = pd.to_datetime(df['date'], errors='coerce')
        df = df.dropna(subset=['date'])
        df['server'] = df['server'].astype(str)
        for c in ['cpu', 'ram', 'storage']:
            df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
        df = df[['date', 'server', 'cpu', 'ram', 'storage']].rename(columns={'ram': 'ram_gb', 'storage': 'storage_gb'})
        return df
    except Exception as e:
        logger.exception("CSV parse error")
        raise ValueError(f"CSV parsing failed: {e}")

def detect_and_convert_ram_sum_to_gb(raw_sum, raw_max, baseline_gb):
    """Heuristic to decide whether stored ram_delta_gb values are actually MB.
       If max magnitude is huge relative to baseline or > threshold, treat as MB and divide by 1024."""
    try:
        rs = float(raw_sum)
        rm = float(raw_max)
    except Exception:
        return 0.0
    if baseline_gb is None or baseline_gb <= 0:
        if abs(rm) > 1024 * 5:
            return rs / 1024.0
        return rs
    if abs(rm) > abs(baseline_gb) * 10 or abs(rm) > 1024 * 5:
        return rs / 1024.0
    return rs

# ---------- Capacity calculation ----------
def calculate_capacity():
    """
    - Uses filtered inventory rows only (status/location/type).
    - Inventory servermemory is MB -> converted to GB for baseline.
    - Events ram_delta_gb might actually be MB values (legacy); heuristic converts to GB as needed.
    - TOTAL_CAPACITY['STORAGE'] expected in TB in config -> convert to GB for math.
    """
    try:
        inv_sql = """
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024.0, 0) AS ram_gb,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage_gb
            FROM inventory
            WHERE assetstatus IN (:s1, :s2)
              AND assetlocation = :loc
              AND assettype = :atype
        """
        inv = pd.read_sql(text(inv_sql), ENGINE, params={
            "s1": INVENTORY_STATUS[0], "s2": INVENTORY_STATUS[1],
            "loc": INVENTORY_LOCATION, "atype": INVENTORY_TYPE
        })

        baseline_cpu = float(inv['cpu'].iloc[0])
        baseline_ram_gb = float(inv['ram_gb'].iloc[0])
        baseline_storage_gb = float(inv['storage_gb'].iloc[0])

        ev_sql = """
            SELECT
                COALESCE(SUM(cpu_delta), 0) AS cpu_sum,
                COALESCE(SUM(ram_delta_gb), 0) AS ram_sum_raw,
                COALESCE(MAX(ABS(ram_delta_gb)), 0) AS ram_max_raw,
                COALESCE(SUM(storage_delta_gb), 0) AS storage_sum
            FROM capacity_events
        """
        ev = pd.read_sql(text(ev_sql), ENGINE)
        cpu_sum = float(ev['cpu_sum'].iloc[0])
        ram_sum_raw = float(ev['ram_sum_raw'].iloc[0])
        ram_max_raw = float(ev['ram_max_raw'].iloc[0])
        storage_sum = float(ev['storage_sum'].iloc[0])

        # Convert TOTAL_CAPACITY storage TB -> GB for math
        total_storage_tb = TOTAL_CAPACITY.get("STORAGE", 0)
        total_storage_gb = total_storage_tb * 1024.0

        # Convert event ram sum to GB (if necessary)
        ram_sum_gb = detect_and_convert_ram_sum_to_gb(ram_sum_raw, ram_max_raw, baseline_ram_gb)

        used_cpu = baseline_cpu + cpu_sum
        used_ram_gb = baseline_ram_gb + ram_sum_gb
        used_storage_gb = baseline_storage_gb + storage_sum

        results = {}
        for key in ("CPU", "RAM", "STORAGE"):
            if key == "STORAGE":
                total = total_storage_gb
            else:
                total = TOTAL_CAPACITY.get(key, 0)
            reserved = total * RESERVED_PERCENT
            usable = max(total - reserved, 0)
            used_val = {"CPU": used_cpu, "RAM": used_ram_gb, "STORAGE": used_storage_gb}[key]
            pct = (used_val / usable * 100) if usable > 0 else 0
            available = max(usable - used_val, 0)
            results[key] = {
                "used": used_val,
                "total": total,
                "reserved": reserved,
                "usable": usable,
                "available": available,
                "pct": pct
            }
        logger.info("Capacity results: %s", results)
        return results
    except Exception as e:
        logger.exception("calculate_capacity failed")
        return {
            "CPU": {"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0},
            "RAM": {"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0},
            "STORAGE": {"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0}
        }

# ---------- Trend builder ----------
def build_trend(resource):
    """Nice-looking trend: baseline dotted, used filled line, usable dashed. For STORAGE chart units in TB."""
    try:
        inv_sql = """
            SELECT
                COALESCE(SUM(NULLIF(TRIM(servercores), '')::numeric), 0) AS cpu,
                COALESCE(SUM(NULLIF(TRIM(servermemory), '')::numeric)/1024.0, 0) AS ram_gb,
                COALESCE(SUM(NULLIF(TRIM(totaldisk), '')::numeric), 0) AS storage_gb
            FROM inventory
            WHERE assetstatus IN (:s1, :s2)
              AND assetlocation = :loc
              AND assettype = :atype
        """
        inv = pd.read_sql(text(inv_sql), ENGINE, params={
            "s1": INVENTORY_STATUS[0], "s2": INVENTORY_STATUS[1],
            "loc": INVENTORY_LOCATION, "atype": INVENTORY_TYPE
        })
        baseline = float(inv[resource.lower() if resource != "RAM" else "ram_gb"].iloc[0])

        # usable line
        if resource == "STORAGE":
            total_gb = TOTAL_CAPACITY.get("STORAGE", 0) * 1024.0
            usable_line = max(total_gb - total_gb * RESERVED_PERCENT, 0)
        else:
            total = TOTAL_CAPACITY.get(resource, 0)
            usable_line = max(total - total * RESERVED_PERCENT, 0)

        today = datetime.today().date()
        start = today - timedelta(days=30)

        df = pd.read_sql(text("""
            SELECT DATE(event_time) AS d,
                   SUM(
                       CASE
                           WHEN :r = 'CPU' THEN COALESCE(cpu_delta, 0)
                           WHEN :r = 'RAM' THEN COALESCE(ram_delta_gb, 0)
                           WHEN :r = 'STORAGE' THEN COALESCE(storage_delta_gb, 0)
                           ELSE 0
                       END
                   ) AS v
            FROM capacity_events
            WHERE event_time >= :start_date
            GROUP BY DATE(event_time)
            ORDER BY d
        """), ENGINE, params={"r": resource, "start_date": start})

        date_range = pd.date_range(start, today)
        if df.empty:
            df = pd.DataFrame({"d": date_range, "v": 0})
        else:
            df = df.set_index('d').reindex(date_range).fillna(0).reset_index()
            df.columns = ['d', 'v']

        # RAM event detection & convert if stored in MB
        if resource == "RAM":
            if df['v'].abs().max() > (abs(baseline) * 10 if baseline > 0 else 1024 * 5):
                df['v'] = df['v'] / 1024.0

        df['used'] = baseline + df['v'].cumsum()

        # For storage chart, convert to TB for readability
        if resource == "STORAGE":
            df['plot'] = df['used'] / 1024.0  # TB
            baseline_plot = baseline / 1024.0
            usable_plot = usable_line / 1024.0
            y_label = "Used (TB)"
        else:
            df['plot'] = df['used']
            baseline_plot = baseline
            usable_plot = usable_line
            y_label = "Used (cores)" if resource == "CPU" else "Used (GB)"

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=df['d'], y=df['plot'], mode='lines', line=dict(color='#0b5ed7', width=2), fill='tozeroy', name='Used'))
        fig.add_trace(go.Scatter(x=[df['d'].iloc[0], df['d'].iloc[-1]], y=[baseline_plot, baseline_plot],
                                 mode='lines', line=dict(color='rgba(11,94,215,0.6)', dash='dot'), name='Baseline'))
        if usable_plot > 0:
            fig.add_trace(go.Scatter(x=[df['d'].iloc[0], df['d'].iloc[-1]], y=[usable_plot, usable_plot],
                                     mode='lines', line=dict(color='rgba(220,53,69,0.6)', dash='dash'), name='Usable'))

        fig.update_layout(template="plotly_white", title=f"{resource} Usage - Last 30 Days",
                          xaxis_title="Date", yaxis_title=y_label, height=360,
                          margin=dict(t=40, b=30, l=40, r=20),
                          legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
        return fig
    except Exception as e:
        logger.exception("build_trend failed")
        return go.Figure()

# ---------- Dash app ----------
external_styles = [dbc.themes.FLATLY]
app = Dash(__name__, external_stylesheets=external_styles)
app.title = "Capacity Dashboard"

# Navbar
navbar = dbc.Navbar(
    dbc.Container([
        dbc.NavbarBrand("Capacity Dashboard", className="text-white"),
        dbc.Button("Refresh", id="refresh", color="light")
    ]),
    color="#0b5ed7",
    dark=True,
    className="mb-3"
)

# Instructions card for events
events_instructions = dbc.Card(
    dbc.CardBody([
        html.H6("Events — How to enter data", className="mb-2"),
        html.Ul([
            html.Li("CPU Δ: cores (e.g. 2 or -1)"),
            html.Li("RAM Δ: GB (e.g. 8 or -4) — this will be converted to MB in DB"),
            html.Li("Storage Δ: GB (e.g. 100 or -50)"),
            html.Li("Server: exact assetuniquename (to tie to inventory baseline)"),
        ], style={"fontSize":"0.9rem"}),
        html.H6("CSV format", className="mt-2"),
        html.P("CSV headers (case-insensitive): date,server,cpu,ram,storage. ram/storage in GB.", style={"fontSize":"0.9rem"}),
        html.Pre("date,server,cpu,ram,storage\n2026-01-10,web-01,2,8,100", style={"fontSize":"0.85rem"})
    ]),
    className="mb-2"
)

# Layout
app.layout = dbc.Container([
    navbar,
    html.Div([
        html.H2("Capacity Management Dashboard", style={"color":"#0b5ed7"}),
        html.P("Filtered: Running servers in NJ Datacenter (Server/VM)", style={"color":"#495057"})
    ], className="mb-3"),
    dcc.Interval(id="interval", interval=5*60*1000, n_intervals=0),

    dbc.Tabs([
        dbc.Tab(label="Dashboard", children=[
            html.H4("KPIs", className="mt-3"),
            dbc.Row(id="kpi-row", className="g-4 mb-4"),
            html.H4("30-Day Trends", className="mt-3"),
            dbc.Row([
                dbc.Col(dcc.Graph(id="cpu-trend"), md=4),
                dbc.Col(dcc.Graph(id="ram-trend"), md=4),
                dbc.Col(dcc.Graph(id="storage-trend"), md=4)
            ]),
            html.Div(id="alerts", className="mt-3")
        ]),

        dbc.Tab(label="Events", children=[
            dbc.Row([
                dbc.Col(events_instructions, md=3),
                dbc.Col(
                    dbc.Card(
                        dbc.CardBody([
                            html.H5("Add Event", className="mb-2"),
                            dbc.Row([
                                dbc.Col(dbc.Label("Server (required)"), md=12),
                                dbc.Col(dbc.Input(id="server", placeholder="assetuniquename"), md=12)
                            ], className="mb-2"),
                            dbc.Row([
                                dbc.Col(dbc.Label("CPU Δ (cores)"), md=6),
                                dbc.Col(dbc.Label("RAM Δ (GB)"), md=6)
                            ]),
                            dbc.Row([
                                dbc.Col(dbc.Input(id="cpu", type="number", placeholder="e.g. 2"), md=6),
                                dbc.Col(dbc.Input(id="ram", type="number", placeholder="e.g. 8"), md=6)
                            ], className="mb-2"),
                            dbc.Row([
                                dbc.Col(dbc.Label("Storage Δ (GB)"), md=12),
                                dbc.Col(dbc.Input(id="storage", type="number", placeholder="e.g. 100"), md=12)
                            ], className="mb-3"),
                            dbc.Button("Submit Event", id="submit", color="primary", className="w-100"),
                            html.Div(id="msg", className="mt-2"),
                            html.Hr(),
                            dcc.Upload(
                                id="csv-upload",
                                children=dbc.Button("Upload CSV", color="secondary", className="w-100"),
                                multiple=False
                            ),
                            html.Div(id="csv-msg", className="mt-2")
                        ])
                    ), md=5
                ),
                dbc.Col(
                    dbc.Card(dbc.CardBody([
                        html.H5("Recent Events (last 10)", className="mb-2"),
                        html.Div(id="recent-events")
                    ])), md=4
                )
            ], className="mt-3")
        ]),

        dbc.Tab(label="Inventory", children=[
            html.H4("Filtered Inventory", className="mt-3"),
            html.P("Showing: assetstatus IN ('Running','Running/Not in Production'), assetlocation = 'NJ Datacenter', assettype = 'Server/VM'", style={"fontSize":"0.9rem"}),
            html.Div(id="inventory-table", className="mt-2")
        ])
    ])
], fluid=True)

# ---------- Callbacks ----------
@app.callback(
    [
        Output("kpi-row", "children"),
        Output("alerts", "children"),
        Output("cpu-trend", "figure"),
        Output("ram-trend", "figure"),
        Output("storage-trend", "figure"),
        Output("recent-events", "children"),
        Output("inventory-table", "children"),
        Output("msg", "children"),
        Output("csv-msg", "children")
    ],
    [
        Input("submit", "n_clicks"),
        Input("csv-upload", "contents"),
        Input("interval", "n_intervals"),
        Input("refresh", "n_clicks")
    ],
    [
        State("server", "value"),
        State("cpu", "value"),
        State("ram", "value"),
        State("storage", "value"),
        State("csv-upload", "filename")
    ],
    prevent_initial_call=False
)
def master_callback(submit_n, csv_contents, n_intervals, refresh_n, server, cpu, ram, storage, filename):
    ctx = callback_context
    triggered = ctx.triggered[0]['prop_id'] if ctx.triggered else ""
    triggered_id = triggered.split('.')[0] if triggered else ""

    msg = no_update
    csv_msg = no_update
    refresh_needed = False

    # Manual submit
    if triggered_id == "submit" and submit_n:
        if not server or str(server).strip() == "":
            msg = dbc.Alert("Server (assetuniquename) is required", color="danger")
        elif (cpu is None or float(cpu) == 0) and (ram is None or float(ram) == 0) and (storage is None or float(storage) == 0):
            msg = dbc.Alert("Provide at least one non-zero delta (CPU, RAM or Storage)", color="danger")
        else:
            try:
                # Convert RAM from GB -> MB for DB storage
                ram_mb = 0.0
                if ram is not None:
                    ram_mb = float(ram) * 1024.0
                with ENGINE.begin() as conn:
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time)
                        VALUES (:s, :c, :r, :st, 'MANUAL', now())
                    """), {"s": server, "c": float(cpu or 0), "r": ram_mb, "st": float(storage or 0)})
                msg = dbc.Alert("Event saved (RAM converted to MB for DB).", color="success")
                refresh_needed = True
            except Exception as e:
                logger.exception("manual insert failed")
                msg = dbc.Alert(f"Error saving event: {e}", color="danger")

    # CSV upload
    if triggered_id == "csv-upload" and csv_contents:
        try:
            df = parse_csv(csv_contents, filename)
            with ENGINE.begin() as conn:
                for _, row in df.iterrows():
                    ram_mb = float(row['ram_gb']) * 1024.0
                    conn.execute(text("""
                        INSERT INTO capacity_events
                        (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time)
                        VALUES (:server, :cpu, :ram, :storage, 'CSV', :date)
                    """), {
                        "server": row['server'],
                        "cpu": float(row['cpu']),
                        "ram": ram_mb,
                        "storage": float(row['storage_gb']),
                        "date": row['date']
                    })
            csv_msg = dbc.Alert(f"Imported {len(df)} rows (RAM GB→MB on save)", color="success")
            refresh_needed = True
        except Exception as e:
            logger.exception("csv import failed")
            csv_msg = dbc.Alert(f"CSV error: {e}", color="danger")

    # Refresh triggers (initial load, interval, refresh button, or after edits)
    if refresh_needed or triggered_id in ("interval", "refresh") or triggered_id == "":
        cap = calculate_capacity()

        # KPI cards
        kpi_children = []
        alerts = []
        for k in ("CPU", "RAM", "STORAGE"):
            d = cap[k]
            pct = d.get("pct", 0)
            if pct > 100:
                color = "danger"
            elif pct > 90:
                color = "danger"
            elif pct > 80:
                color = "warning"
            else:
                color = "primary"

            if k == "CPU":
                used_text = fmt_cpu(d['used'])
                total_text = fmt_cpu(d['total'])
                reserved_text = fmt_cpu(d['reserved'])
                usable_text = fmt_cpu(d['usable'])
                available_text = fmt_cpu(d['available'])
            elif k == "RAM":
                used_text = fmt_ram_gb(d['used'])
                total_text = fmt_ram_gb(d['total'])
                reserved_text = fmt_ram_gb(d['reserved'])
                usable_text = fmt_ram_gb(d['usable'])
                available_text = fmt_ram_gb(d['available'])
            else:  # STORAGE: d values are in GB; show TB in UI
                used_text = fmt_storage_tb_from_gb(d['used'])
                total_text = fmt_storage_tb_from_gb(d['total'])
                reserved_text = fmt_storage_tb_from_gb(d['reserved'])
                usable_text = fmt_storage_tb_from_gb(d['usable'])
                available_text = fmt_storage_tb_from_gb(d['available'])

            card = dbc.Card(
                dbc.CardBody([
                    html.H6(k, className="mb-1"),
                    html.H4(used_text, className="mb-2"),
                    html.Div([
                        html.Small(f"Total: {total_text}", className="me-3"),
                        html.Small(f"Reserved: {reserved_text}", className="me-3"),
                        html.Small(f"Usable: {usable_text}")
                    ], className="d-flex flex-wrap mb-2"),
                    dbc.Progress(value=min(pct, 100), color=color, style={"height":"18px"}),
                    html.Div(className="d-flex justify-content-between mt-2", children=[
                        html.Small(f"Available: {available_text}"),
                        html.Small(f"{pct:.1f}%")
                    ])
                ]), className="shadow-sm"
            )
            kpi_children.append(dbc.Col(card, md=4))

            if pct > 90:
                alerts.append(dbc.Alert(f"High {k} utilization ({pct:.1f}%)", color="warning", dismissable=True))

        # Trends
        cpu_trend = build_trend("CPU")
        ram_trend = build_trend("RAM")
        storage_trend = build_trend("STORAGE")

        # Recent events
        recent_df = pd.read_sql("""
            SELECT event_time, assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb
            FROM capacity_events
            ORDER BY event_time DESC LIMIT 10
        """, ENGINE)
        if not recent_df.empty:
            def show_ram(v):
                try:
                    vv = float(v)
                except:
                    return v
                # if stored as MB (large), convert back to GB for display
                if abs(vv) > 1024 * 2:
                    return f"{vv/1024:.2f} GB"
                return f"{vv:.2f} GB"
            recent_df = recent_df.rename(columns={
                "event_time": "Event Time",
                "assetuniquename": "Server",
                "cpu_delta": "CPU Δ",
                "ram_delta_gb": "RAM Δ",
                "storage_delta_gb": "Storage Δ (GB)"
            })
            recent_df["RAM Δ"] = recent_df["RAM Δ"].apply(show_ram)
            recent_table = dbc.Table.from_dataframe(recent_df, striped=True, hover=True, bordered=True, responsive=True)
        else:
            recent_table = html.P("No recent events", className="text-center text-muted p-4")

        # Inventory table (exact columns per your FYI SQL)
        inv_sql = """
            SELECT
                assetipaddress,
                servercores,
                servermemory,
                totaldisk,
                assetstatus
            FROM inventory
            WHERE assetstatus IN (:s1, :s2)
              AND assetlocation = :loc
              AND assettype = :atype
            ORDER BY assetipaddress
        """
        inv_df = pd.read_sql(text(inv_sql), ENGINE, params={
            "s1": INVENTORY_STATUS[0], "s2": INVENTORY_STATUS[1],
            "loc": INVENTORY_LOCATION, "atype": INVENTORY_TYPE
        })

        if not inv_df.empty:
            # Convert servermemory (MB) -> GB for display, keep header unit only
            inv_df = inv_df.rename(columns={
                "assetipaddress": "IP Address",
                "servercores": "CPU (cores)",
                "servermemory": "RAM (GB)",
                "totaldisk": "Storage (GB)",
                "assetstatus": "Status"
            })
            # convert RAM
            def mem_to_gb(x):
                try:
                    return round(float(x) / 1024.0, 2)
                except:
                    return "N/A"
            inv_df["RAM (GB)"] = inv_df["RAM (GB)"].apply(mem_to_gb)
            # Keep numeric cells without units; header shows units
            inv_table = dbc.Table.from_dataframe(inv_df[["IP Address", "CPU (cores)", "RAM (GB)", "Storage (GB)", "Status"]], striped=True, hover=True, bordered=True, responsive=True)
        else:
            inv_table = html.P("No inventory records matched filters", className="text-center text-muted p-4")

        return kpi_children, alerts, cpu_trend, ram_trend, storage_trend, recent_table, inv_table, no_update, no_update

    # no change
    return no_update, no_update, no_update, no_update, no_update, no_update, no_update, no_update, no_update

# ---------- Run ----------
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8050, debug=False)
