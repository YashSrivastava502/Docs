#!/usr/bin/env python3
"""
mian.py - Dash dashboard (main app). Uses pending/reconciled flags and excludes reconciled
events from KPI math. New events for missing servers are saved as pending_inventory = true.
"""
import base64, io
from datetime import datetime, timedelta
import pandas as pd
import plotly.graph_objects as go
from sqlalchemy import create_engine, text
import logging
from logging.handlers import TimedRotatingFileHandler
from dash import Dash, dcc, html, Input, Output, State, callback_context, no_update
import dash_bootstrap_components as dbc
from config import DB_CONFIG, TOTAL_CAPACITY, RESERVED_PERCENT

# logging
logger = logging.getLogger("capacity_dashboard")
logger.setLevel(logging.INFO)
handler = TimedRotatingFileHandler("capacity.log", when="midnight", backupCount=7)
handler.setFormatter(logging.Formatter("%(asctime)s - %(levelname)s - %(message)s"))
logger.addHandler(handler)

# DB
ENGINE = create_engine(
    f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}",
    pool_pre_ping=True
)

# Inventory filter values
INVENTORY_STATUS = ("Running", "Running/Not in Production")
INVENTORY_LOCATION = "NJ Datacenter"
INVENTORY_TYPE = "Server/VM"

def fmt_cpu(v):
    try: return f"{int(round(float(v))):,} cores"
    except: return "0 cores"
def fmt_ram_gb(v):
    try: return f"{float(v):,.2f} GB"
    except: return "0.00 GB"
def fmt_storage_tb_from_gb(v):
    try: return f"{(float(v)/1024.0):,.2f} TB"
    except: return "0.00 TB"

def parse_csv(contents, filename):
    if not contents: raise ValueError("No file")
    _, content_string = contents.split(",",1)
    decoded = base64.b64decode(content_string)
    df = pd.read_csv(io.StringIO(decoded.decode('utf-8')))
    lc = [c.lower() for c in df.columns]; required = {'date','server','cpu','ram','storage'}
    if not required.issubset(set(lc)): raise ValueError("CSV must have headers: date,server,cpu,ram,storage")
    mapping = {orig: orig.lower() for orig in df.columns}
    df = df.rename(columns=mapping)
    df['date'] = pd.to_datetime(df['date'], errors='coerce'); df = df.dropna(subset=['date'])
    df['server'] = df['server'].astype(str)
    for c in ['cpu','ram','storage']: df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)
    df = df[['date','server','cpu','ram','storage']].rename(columns={'ram':'ram_gb','storage':'storage_gb'})
    return df

def detect_and_convert_ram_sum_to_gb(raw_sum, raw_max, baseline_gb):
    try: rs=float(raw_sum); rm=float(raw_max)
    except: return 0.0
    if baseline_gb <= 0:
        if abs(rm) > 1024*5: return rs/1024.0
        return rs
    if abs(rm) > abs(baseline_gb)*10 or abs(rm) > 1024*5:
        return rs/1024.0
    return rs

def calculate_capacity():
    try:
        inv_sql = """
            SELECT COALESCE(SUM(NULLIF(TRIM(servercores),'')::numeric),0) AS cpu,
                   COALESCE(SUM(NULLIF(TRIM(servermemory),'')::numeric)/1024.0,0) AS ram_gb,
                   COALESCE(SUM(NULLIF(TRIM(totaldisk),'')::numeric),0) AS storage_gb
            FROM inventory
            WHERE assetstatus IN (:s1,:s2) AND assetlocation = :loc AND assettype = :atype
        """
        inv = pd.read_sql(text(inv_sql), ENGINE, params={"s1":INVENTORY_STATUS[0],"s2":INVENTORY_STATUS[1],"loc":INVENTORY_LOCATION,"atype":INVENTORY_TYPE})
        baseline_cpu = float(inv['cpu'].iloc[0]); baseline_ram_gb = float(inv['ram_gb'].iloc[0]); baseline_storage_gb = float(inv['storage_gb'].iloc[0])

        ev_sql = """
            SELECT COALESCE(SUM(cpu_delta) FILTER (WHERE reconciled = false),0) AS cpu_sum,
                   COALESCE(SUM(ram_delta_gb) FILTER (WHERE reconciled = false),0) AS ram_sum_raw,
                   COALESCE(MAX(ABS(ram_delta_gb)) FILTER (WHERE reconciled = false),0) AS ram_max_raw,
                   COALESCE(SUM(storage_delta_gb) FILTER (WHERE reconciled = false),0) AS storage_sum
            FROM capacity_events
        """
        ev = pd.read_sql(text(ev_sql), ENGINE)
        cpu_sum = float(ev['cpu_sum'].iloc[0]); ram_sum_raw = float(ev['ram_sum_raw'].iloc[0]); ram_max_raw = float(ev['ram_max_raw'].iloc[0]); storage_sum = float(ev['storage_sum'].iloc[0])

        total_storage_gb = TOTAL_CAPACITY.get("STORAGE",0) * 1024.0
        ram_sum_gb = detect_and_convert_ram_sum_to_gb(ram_sum_raw, ram_max_raw, baseline_ram_gb)

        used_cpu = baseline_cpu + cpu_sum
        used_ram_gb = baseline_ram_gb + ram_sum_gb
        used_storage_gb = baseline_storage_gb + storage_sum

        results = {}
        for k in ("CPU","RAM","STORAGE"):
            total = total_storage_gb if k=="STORAGE" else TOTAL_CAPACITY.get(k,0)
            reserved = total * RESERVED_PERCENT; usable = max(total-reserved,0); used_val = {"CPU":used_cpu,"RAM":used_ram_gb,"STORAGE":used_storage_gb}[k]
            pct = used_val/usable*100 if usable>0 else 0; available = max(usable-used_val,0)
            results[k] = {"used":used_val,"total":total,"reserved":reserved,"usable":usable,"available":available,"pct":pct}
        return results
    except Exception as e:
        logger.exception("calculate_capacity failed"); return {"CPU":{"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0},"RAM":{"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0},"STORAGE":{"used":0,"total":0,"reserved":0,"usable":0,"available":0,"pct":0}}

def build_trend(resource):
    try:
        inv_sql = "SELECT COALESCE(SUM(NULLIF(TRIM(servercores),'')::numeric),0) as cpu, COALESCE(SUM(NULLIF(TRIM(servermemory),'')::numeric)/1024.0,0) AS ram_gb, COALESCE(SUM(NULLIF(TRIM(totaldisk),'')::numeric),0) AS storage_gb FROM inventory WHERE assetstatus IN (:s1,:s2) AND assetlocation = :loc AND assettype = :atype"
        inv = pd.read_sql(text(inv_sql), ENGINE, params={"s1":INVENTORY_STATUS[0],"s2":INVENTORY_STATUS[1],"loc":INVENTORY_LOCATION,"atype":INVENTORY_TYPE})
        baseline = float(inv['cpu' if resource=="CPU" else ('ram_gb' if resource=="RAM" else 'storage_gb')].iloc[0])
        today = datetime.today().date(); start = today - timedelta(days=30)
        df = pd.read_sql(text("SELECT DATE(event_time) AS d, SUM(CASE WHEN :r='CPU' THEN COALESCE(cpu_delta,0) WHEN :r='RAM' THEN COALESCE(ram_delta_gb,0) WHEN :r='STORAGE' THEN COALESCE(storage_delta_gb,0) END) AS v FROM capacity_events WHERE event_time >= :start_date AND reconciled = false GROUP BY DATE(event_time) ORDER BY d"), ENGINE, params={"r":resource,"start_date":start})
        date_range = pd.date_range(start,today)
        if df.empty:
            df = pd.DataFrame({"d":date_range,"v":0})
        else:
            df = df.set_index('d').reindex(date_range).fillna(0).reset_index(); df.columns=['d','v']
        if resource=="RAM" and df['v'].abs().max() > (abs(baseline)*10 if baseline>0 else 1024*5): df['v'] = df['v']/1024.0
        df['used'] = baseline + df['v'].cumsum()
        if resource=="STORAGE": df['plot']=df['used']/1024.0; y_label="Used (TB)"
        else: df['plot']=df['used']; y_label="Used (cores)" if resource=="CPU" else "Used (GB)"
        fig = go.Figure(); fig.add_trace(go.Scatter(x=df['d'],y=df['plot'],mode='lines',line=dict(color='#0b5ed7',width=2),fill='tozeroy',name='Used'))
        fig.update_layout(template='plotly_white',title=f"{resource} - Last 30 Days",xaxis_title="Date",yaxis_title=y_label,height=340)
        return fig
    except Exception as e:
        logger.exception("build_trend failed"); return go.Figure()

# Dash app
app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
app.title = "Capacity Dashboard"

app.layout = dbc.Container([
    html.H3("Capacity Dashboard"),
    dcc.Interval(id="interval", interval=5*60*1000, n_intervals=0),
    dbc.Tabs([
        dbc.Tab(label="Dashboard", children=[
            html.H4("KPIs"), dbc.Row(id="kpi-row"),
            html.H4("Trends"), dbc.Row([dbc.Col(dcc.Graph(id="cpu-trend")), dbc.Col(dcc.Graph(id="ram-trend")), dbc.Col(dcc.Graph(id="storage-trend"))]),
            html.Div(id="alerts")
        ]),
        dbc.Tab(label="Events", children=[
            html.H5("Add Event"), dbc.Input(id="server", placeholder="assetuniquename", className="mb-2"),
            dbc.Row([dbc.Col(dbc.Input(id="cpu",type="number",placeholder="CPU Δ")), dbc.Col(dbc.Input(id="ram",type="number",placeholder="RAM Δ (GB)"))]),
            dbc.Input(id="storage", type="number", placeholder="Storage Δ (GB)", className="mb-2"),
            dbc.Button("Submit", id="submit", color="primary"), html.Div(id="msg"),
            html.Hr(), html.H5("Upload CSV"), dcc.Upload(id="csv-upload", children=dbc.Button("Upload CSV")), html.Div(id="csv-msg"),
            html.Hr(), html.H5("Recent Events"), html.Div(id="recent-events")
        ]),
        dbc.Tab(label="Inventory", children=[html.H5("Filtered Inventory"), html.Div(id="inventory-table")])
    ])
], fluid=True)

@app.callback(
    [Output("kpi-row","children"), Output("alerts","children"),
     Output("cpu-trend","figure"), Output("ram-trend","figure"), Output("storage-trend","figure"),
     Output("recent-events","children"), Output("inventory-table","children"),
     Output("msg","children"), Output("csv-msg","children")],
    [Input("submit","n_clicks"), Input("csv-upload","contents"), Input("interval","n_intervals")],
    [State("server","value"), State("cpu","value"), State("ram","value"), State("storage","value"), State("csv-upload","filename")],
    prevent_initial_call=False
)
def master(submit_n, csv_contents, n_intervals, server, cpu, ram, storage, filename):
    ctx = callback_context
    triggered = ctx.triggered[0]['prop_id'].split('.')[0] if ctx.triggered else ""
    msg = no_update; csv_msg = no_update
    if triggered == "submit" and submit_n:
        if not server or str(server).strip()=="":
            msg = dbc.Alert("Server required", color="danger")
        elif (cpu is None or float(cpu)==0) and (ram is None or float(ram)==0) and (storage is None or float(storage)==0):
            msg = dbc.Alert("Provide at least one non-zero delta", color="danger")
        else:
            try:
                exists = pd.read_sql(text("SELECT 1 FROM inventory WHERE assetuniquename = :s LIMIT 1"), ENGINE, params={"s": server})
                pending = exists.empty
                ram_mb = float(ram)*1024.0 if ram not in (None,'') else 0.0
                with ENGINE.begin() as conn:
                    conn.execute(text("INSERT INTO capacity_events (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time, pending_inventory, reconciled) VALUES (:s,:c,:r,:st,'MANUAL',now(),:p,false)"), {"s":server,"c":float(cpu or 0),"r":ram_mb,"st":float(storage or 0),"p":pending})
                msg = dbc.Alert(f"Event saved. Pending: {pending}", color="success")
            except Exception as e:
                logger.exception("insert failed"); msg = dbc.Alert(f"Error: {e}", color="danger")

    if triggered == "csv-upload" and csv_contents:
        try:
            df = parse_csv(csv_contents, filename); inserted = 0
            with ENGINE.begin() as conn:
                for _, row in df.iterrows():
                    server_name = row['server']
                    exists = conn.execute(text("SELECT 1 FROM inventory WHERE assetuniquename = :s LIMIT 1"), {"s": server_name}).fetchone()
                    pending = exists is None
                    ram_mb = float(row['ram_gb']) * 1024.0
                    conn.execute(text("INSERT INTO capacity_events (assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb, source, event_time, pending_inventory, reconciled) VALUES (:s,:c,:r,:st,'CSV',:date,:p,false)"), {"s":server_name,"c":float(row['cpu']),"r":ram_mb,"st":float(row['storage_gb']),"date":row['date'],"p":pending})
                    inserted += 1
            csv_msg = dbc.Alert(f"Imported {inserted} rows", color="success")
        except Exception as e:
            logger.exception("CSV import failed"); csv_msg = dbc.Alert(f"CSV error: {e}", color="danger")

    cap = calculate_capacity()
    kpi_cards = []; alerts = []
    for k in ("CPU","RAM","STORAGE"):
        d = cap[k]; pct = d.get("pct",0)
        color = "danger" if pct>90 else "warning" if pct>80 else "primary"
        if k=="CPU":
            used_text = fmt_cpu(d['used']); total_text = fmt_cpu(d['total']); reserved_text = fmt_cpu(d['reserved']); usable_text = fmt_cpu(d['usable']); available_text = fmt_cpu(d['available'])
        elif k=="RAM":
            used_text = fmt_ram_gb(d['used']); total_text = fmt_ram_gb(d['total']); reserved_text = fmt_ram_gb(d['reserved']); usable_text = fmt_ram_gb(d['usable']); available_text = fmt_ram_gb(d['available'])
        else:
            used_text = fmt_storage_tb_from_gb(d['used']); total_text = fmt_storage_tb_from_gb(d['total']); reserved_text = fmt_storage_tb_from_gb(d['reserved']); usable_text = fmt_storage_tb_from_gb(d['usable']); available_text = fmt_storage_tb_from_gb(d['available'])
        card = dbc.Card(dbc.CardBody([html.H6(k), html.H4(used_text), html.Div([html.Small(f"Total: {total_text}", className="me-3"), html.Small(f"Reserved: {reserved_text}", className="me-3"), html.Small(f"Usable: {usable_text}")]), dbc.Progress(value=min(pct,100), color=color, style={"height":"18px"}), html.Div(className="d-flex justify-content-between mt-2", children=[html.Small(f"Available: {available_text}"), html.Small(f"{pct:.1f}%")])]))
        kpi_cards.append(dbc.Col(card, md=4)); 
        if pct>90: alerts.append(dbc.Alert(f"High {k} utilization ({pct:.1f}%)", color="warning", dismissable=True))

    cpu_trend = build_trend("CPU"); ram_trend = build_trend("RAM"); storage_trend = build_trend("STORAGE")
    recent_df = pd.read_sql(text("SELECT event_time, assetuniquename, cpu_delta, ram_delta_gb, storage_delta_gb FROM capacity_events ORDER BY event_time DESC LIMIT 100"), ENGINE)
    if not recent_df.empty:
        def show_ram(v):
            try: vv=float(v)
            except: return v
            if abs(vv)>1024*2: return f"{vv/1024:.2f} GB"
            return f"{vv:.2f} GB"
        recent_df = recent_df.rename(columns={"event_time":"Event Time","assetuniquename":"Server","cpu_delta":"CPU Δ","storage_delta_gb":"Storage Δ (GB)"})
        recent_df["RAM Δ"] = recent_df["ram_delta_gb"].apply(show_ram)
        recent_table = dbc.Table.from_dataframe(recent_df[["Event Time","Server","CPU Δ","RAM Δ","Storage Δ (GB)"]], striped=True, hover=True, bordered=True, responsive=True)
    else: recent_table = html.P("No recent events", className="text-muted")

    inv_df = pd.read_sql(text("SELECT assetuniquename AS \"Server Name\", assetipaddress AS \"IP Address\", servercores AS \"CPU (cores)\", ROUND(COALESCE(NULLIF(TRIM(servermemory),'')::numeric / 1024.0, 0), 2) AS \"RAM (GB)\", totaldisk AS \"Storage (GB)\", assetstatus AS \"Status\" FROM inventory WHERE assetstatus IN ('Running','Running/Not in Production') AND assetlocation = :loc AND assettype = :atype ORDER BY assetuniquename"), ENGINE, params={"loc":"NJ Datacenter","atype":"Server/VM"}).fillna("N/A")
    inv_table = dbc.Table.from_dataframe(inv_df[["Server Name","IP Address","CPU (cores)","RAM (GB)","Storage (GB)","Status"]], striped=True, hover=True, bordered=True, responsive=True) if not inv_df.empty else html.P("No inventory matching filters", className="text-muted")

    return kpi_cards, alerts, cpu_trend, ram_trend, storage_trend, recent_table, inv_table, msg, csv_msg

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8050, debug=False)
