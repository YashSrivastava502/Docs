#!/usr/bin/env python3
import logging
import pandas as pd
from datetime import datetime
from database import get_engine

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler("logs/snapshot_refresh.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def refresh():
    logger.info("Refreshing snapshot")

    try:
        engine = get_engine()

        # Latest baseline
        master = pd.read_sql("""
            SELECT total_storage_gb, total_ram_gb, total_cpu_cores
            FROM server_capacity_master
            ORDER BY last_updated DESC LIMIT 1
        """, engine).iloc[0]

        # All-time net deltas
        deltas = pd.read_sql("""
            SELECT resource_type, SUM(change_value) AS delta
            FROM server_capacity_events
            GROUP BY resource_type
        """, engine).set_index("resource_type")["delta"].to_dict()

        used_storage = master["total_storage_gb"] + deltas.get("storage", 0)
        used_ram     = master["total_ram_gb"]     + deltas.get("ram",     0)
        used_cpu     = master["total_cpu_cores"]  + deltas.get("cpu",     0)

        used_storage = max(0, used_storage)
        used_ram     = max(0, used_ram)
        used_cpu     = max(0, used_cpu)

        with engine.connect() as conn:
            conn.execute("""
                INSERT INTO server_capacity_snapshot
                (storage_used_gb, ram_used_gb, cpu_used_cores, snapshot_time)
                VALUES (%s, %s, %s, NOW())
            """, (used_storage, used_ram, used_cpu))
            conn.commit()

        logger.info(
            f"Snapshot updated â†’ "
            f"Storage: {used_storage:,.1f} GB | "
            f"RAM: {used_ram:,.1f} GB | "
            f"CPU: {used_cpu:,.0f} cores"
        )

    except Exception as e:
        logger.error("Snapshot refresh failed", exc_info=True)


if __name__ == "__main__":
    refresh()
